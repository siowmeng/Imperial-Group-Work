---
title: "Analysis of IMDB Movie Dataset"
date: "16 October 2016"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggthemes)
library(ggrepel)
library(reshape2)
library(dplyr)
library(plyr)
library(caret)
```


#Executive Summary
*to be filled out after we have finished our analysis*

#Introduction

*Introduction to go here (person to fill out TBD)*
*key purpose/concepts that we are trying to explore are what makes a movie popular (based on the gross revenue), and what makes a movie highly rated by the public (based on the imdb score)*

#Data

```{r, echo = FALSE}
movies <- read.csv(file = "movie_metadata.csv", header = TRUE, stringsAsFactors = FALSE, strip.white = TRUE)
```

*Explanation of the data and how it was extracted from IMDB to go here - Steven L*

* explain what IMDB is

The dataset used for this analysis was downloaded from Kaggle. The data was scraped from IMDB website using "Scrapy", a Python library. It contains `r dim(movies)[1]` movies with `r dim(movies)[2]` variables spanning 100 years and 66 countries. The dataset can be retrieved [here](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset).

The dataset includes the following columns:
`r names(movies)`

*also to potentially include as discussed: explanation of each of the columns and what they mean (box office gross or total gross including dvd sales etc.? and budget as final budget or expected budget?*

# Data Cleansing

*As we agreed in the discussion - feel free to let me know if I made any mistakes - Louise to take the code from George/Stephen and add in the steps agreed below*

First we look into the amount of NA variables found in each column our data:

```{r, echo = FALSE}
## function to calculate list of NAs within a column
colNA <- function(dfCol){ sum(is.na(dfCol)) }
## To show table of sum of NAs by column
apply(movies, 2, colNA)
```

The following cleansing process is then applied:

* All rows where the title year is NA are removed - as there are a high number, and this variable is not expected to be key to the analysis.
* All rows where gross is NA are removed - as there are a high number, and this variable is expected to be one of the output variables
* All rows where the budget is NA are removed - as there are a high number, and this variable is expected to be key to the analysis.
* The aspect ratio column is removed - as there are a high number of NAs, and this variable is not expected to be key to the analysis. (*Louise comment - should we justify this somewhere?*)
* The IMDB link column is removed - as this variable is not expected to be key to the analysis

After this point there are only a few NAs remaining.

```{r, echo = FALSE}
## To remove rows where NAs are present for any of the applicable columns
movies <- movies[complete.cases(movies[c("title_year","budget","gross")]),]
## To remove aspect ratio and imdb link columns
movies$aspect_ratio<- NULL
movies$movie_imdb_link<- NULL
## To show table of sum of NAs by column
apply(movies, 2, colNA)
```

* For all other columns where there are NAs, the mean value will be used to replace all NAs within that column. Although this has some drawbacks in terms of accuracy, it allows us to maintain rows of data with other valid information, and is an unbiased approach to handling NAs.
*Louise comment - I will find some literature on this and explain it better*
```{r, echo = FALSE}
## for loop to replace NAs with means for particular columns
for (i in c("actor_1_facebook_likes" , "actor_2_facebook_likes" , "actor_3_facebook_likes" , "num_critic_for_reviews" , "duration" , "facenumber_in_poster"))
 {k <- which(colnames(movies)==i)
 movies[k][is.na(movies[k]==TRUE)] <- round(mean(movies[[k]], na.rm=TRUE),0)}
```

* Unwanted strings "Â" as well as leading and trailing white spaces are removed from the "title" column.

```{r, echo = FALSE}
movies <- movies[!duplicated(movies$movie_title),]
# Function to remove Â, leading and trailing whitespace from movies$movie_title
movie_title_processing <- function(str){
  str <- sub(pattern = "Â", replacement = "", str)
  str <- sub(pattern = "^\\s+|\\s+$", replacement ="", str)
}
# Apply previous function
movies$movie_title <- sapply(movies$movie_title, FUN = movie_title_processing)
```

Although some of these steps reduce the sample size for analysis, the rows removed would either cause later analysis to fail, cause the dataset to be inconsistent across various pieces of analysis, or produce misleading results.

This cleansed dataset (of `r nrow(movies)` rows) contains no NA values and is used for the remainder of the analysis.

```{r, echo = FALSE}
apply(movies, 2, colNA)
```
*General note: I plan to tidy up the writing here later but just wanted to get down our discussion :)*

*Siow Meng comment: I think there's bug in below code, the dataframe movies has already been subsetted once before test set is assigned*  
*Louise - I'm not sure I understand what bug you're describing - let's talk about it*

```{r, echo = FALSE, message = FALSE}
set.seed(1)
intrain <- createDataPartition(y = movies[[1]], p = 0.9, list = FALSE)
movies <- movies[intrain, ]
test <- movies[-intrain, ]
```

10% of the cleansed dataset (`r nrow(test)`) is then set aside to be the "test" dataset, leaving the remaining 90%  of our dataset (`r nrow(movies)`) as the training dataset. The training dataset alone will be used for all descriptive, inferential and predictive analysis, including model building. The "test" dataset will be used at a later stage to check the accuracy of the predicted model.


# Descriptive Data Analysis

*For now, each have a section with one (or more) descriptive plot, later we can discuss how this flows into a narrative - we should let everyone in the slack group know what we're doing so that we don't overlap unecessarily**

*different options we discussed are:*

* *Map diagram with bubbles showing movies by country*
* *Time analysis - multiple boxplots for each decade (LF note: could also be under inference - if you then want to discuss whether decade is a good predictor of revenue - might get different results if you take decade as a number or a factor)*
* *imdb score against gross coloured by: actor/director/country*
* *frequency of movies with different genres/keywords - (George has already done this)*
* *Ratings broken down by genre (boxplot)*
* *Top actors in terms of facebook likes*
* *Analysis of top movies (by score and gross)*
* *Total number of facebook likes - histogram*

### Siow Meng

```{r, echo = FALSE}

revYear <- ddply(movies, ~ title_year, summarise, meanRev = mean(gross, na.rm = TRUE))

ggplot(data = revYear, aes(x = title_year, y = meanRev)) + geom_line() + labs(title = "Average Gross Revenue from Year 1920 to 2016", x = "Year", y = "Average Revenue") + coord_cartesian(xlim = c(1920, 2016))

revLanguage <- ddply(movies, ~ title_year + language, summarise, meanRev = mean(gross, na.rm = TRUE))

ggplot(data = revLanguage[revLanguage$language == "English", ], aes(x = title_year, y = meanRev)) + geom_line() + labs(title = "Average Gross Revenue of English Movies from Year 1920 to 2016", x = "Year", y = "Average Revenue") + coord_cartesian(xlim = c(1920, 2016))

ggplot(data = revLanguage[revLanguage$language != "English", ], aes(x = title_year, y = meanRev)) + geom_line() + labs(title = "Average Gross Revenue of Non-English Movies from Year 1920 to 2016", x = "Year", y = "Average Revenue") + coord_cartesian(xlim = c(1920, 2016))

# Correlation plot from Louise

moviesnumeric<- movies[c("duration", "title_year", "budget", "imdb_score", "movie_facebook_likes", "actor_1_facebook_likes", "actor_2_facebook_likes", "actor_3_facebook_likes", "cast_total_facebook_likes", "director_facebook_likes", "num_user_for_reviews", "num_critic_for_reviews", "facenumber_in_poster", "gross")]

##used pairwise complete obs to handle NAs for fields with a high number of nas
corrmatrix <- round(cor(moviesnumeric, use="pairwise.complete.obs"), 2)
meltedmovies<- melt(corrmatrix)
ggplot(data = meltedmovies, aes(x=Var1, y=Var2, fill=value)) + geom_tile() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x="", y="") + ggtitle("Correlation Matrix")

# Added correlation plot for movies after 2005
corrmatrix2005 <- round(cor(moviesnumeric[moviesnumeric$title_year >= 2005, ], use="pairwise.complete.obs"), 2)
meltedmovies2005 <- melt(corrmatrix2005)
ggplot(data = meltedmovies2005, aes(x=Var1, y=Var2, fill=value)) + geom_tile() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x="", y="") + ggtitle("Correlation Matrix")

# Added correlation plot for movies after 2010
corrmatrix2010 <- round(cor(moviesnumeric[moviesnumeric$title_year >= 2010, ], use="pairwise.complete.obs"), 2)
meltedmovies2010 <- melt(corrmatrix2010)
ggplot(data = meltedmovies2010, aes(x=Var1, y=Var2, fill=value)) + geom_tile() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x="", y="") + ggtitle("Correlation Matrix")

```

### Nikhita

Will do a country/actor analysis on gross and imdb score.

*Siow Meng comment: I commented Nikhita's code for now as it is giving error while knitting the file. To investigate further.*  

*Siow Meng comment: Might want to avoid keyword: head*  


```{r}

country <- movies$country
scores <- movies$imdb_score

# # Sorting the movies by country and picking out the top 10
# counted <- count(movies, country)
# sorted <- arrange(counted, desc(n))
# head <- sorted[1:10,]
# head$country <- factor(head$country, levels = head$country[order(head$n)])
# 
# ggplot(head, aes(x = country, y = n, fill = country, label = n)) + geom_bar(stat="identity") + coord_flip()
# 
# USA <- subset(movies, country == "USA")
# UK <- subset(movies, country == "UK")
# Fra <- subset(movies, country == "France")
# Ger <- subset(movies, country == "Germany")
# Can <- subset(movies, country == "Canada")
# Aus <- subset(movies, country == "Australia")
# Spa <- subset(movies, country == "Spain")
# Jap <- subset(movies, country == "Japan")
# Chi <- subset(movies, country == "China")
# Ind <- subset(movies, country == "India")
# 
# # Plotting graph for gross vs imdb score (Need to figure out a one-step way of doing this)
# ggplot(USA, aes(x = gross, y = imdb_score)) + geom_point(colour = "red")
# ggplot(UK, aes(x = gross, y = imdb_score)) + geom_point(colour = "blue")
# ggplot(Fra, aes(x = gross, y = imdb_score)) + geom_point(colour = "green")
# ggplot(Ger, aes(x = gross, y = imdb_score)) + geom_point(colour = "pink")
# ggplot(Can, aes(x = gross, y = imdb_score)) + geom_point()
# ggplot(Aus, aes(x = gross, y = imdb_score)) + geom_point()
# ggplot(Spa, aes(x = gross, y = imdb_score)) + geom_point()
# ggplot(Jap, aes(x = gross, y = imdb_score)) + geom_point()
# ggplot(Chi, aes(x = gross, y = imdb_score)) + geom_point()
# ggplot(Ind, aes(x = gross, y = imdb_score)) + geom_point()

```


### Cecilia

Will do a plot for budget vs gross and budget vs imdb score *test*

### George

Will do an analysis on *Gross revenue* and *IMDB score* based on *Genres* and *Plot Keywords*. :)

# Genres

Descriptive analysis based on the movies genres and how do they correlate possibly with other variables of the dataset. Genres with less than 10 movies have been omitted. The first graph shows the number of movies in each genre while the second and the third plots present a boxplot for each genre associated with the profit of the movies and the IMDB score of the movies respectively.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
genres <- c()
i <- 1
for (ins in movies$genres){
    g <- strsplit(ins, "[|]")
    for (gnr in g[[1]]){
        if (!(gnr %in% genres)){
            genres[i] <- gnr
            i = i + 1
        }
    }
}
# Create a dataframe with logical values which 
# indiacte the categories of each movie
movies$genres <- strsplit(movies$genres, "[|]")
genres_idx <- movies[, c("movie_title", "genres")]
i = 1
mat <- matrix(rep(0, (dim(movies)[1] * length(genres))), nrow = dim(movies)[1])
for (g in genres_idx$genres){
    idx <- which(genres %in% g)
    mat[i, idx] <- 1
    i = i + 1
}
colnames(mat) <- genres
movies_and_genres <- data.frame(mat)

# Find how many movies belong in each genre
sum <- rep(0, length(genres))
for (i in 1:length(genres)){
    sum[i] <- sum(movies_and_genres[, i])
}
genres_sum <- data.frame(genre = factor(genres), sum = sum)
genres_sum <- genres_sum[order(sum, decreasing = FALSE),]
genres_sum$genre <- factor(genres_sum$genre, levels = genres_sum$genre)
genres_sum <- genres_sum[genres_sum$sum > 10, ]

# Number of movies belonging to each genre
ggplot(genres_sum, aes(x = genre, y = sum, fill = genre)) + 
    geom_bar(stat = "identity", colour = "black") + 
    coord_flip() +
    labs(title = "Number of movies by genre", x = "", y = "") + 
    geom_text(aes(label = sum), hjust = -0.2, vjust = 0.4) + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.text.x=element_blank(), axis.ticks.x = element_blank(), axis.ticks.y = element_blank()) 

######################### Create an appropriate dataframe with gross, imdb_score and genres for each movie
movies_and_genres <- cbind(gross = movies$gross, score = movies$imdb_score, movies_and_genres, stringsAsFactors = FALSE)
movies_and_genres <- melt(movies_and_genres, id = c("gross", "score"))
movies_and_genres <- movies_and_genres[movies_and_genres$value == 1, ] 
movies_and_genres$value <- NULL
colnames(movies_and_genres) <- c("gross", "score", "genre")
movies_and_genres$genre <- factor(movies_and_genres$genre, levels = genres_sum$genre)
movies_and_genres <- movies_and_genres[complete.cases(movies_and_genres), ]

# Boxplot of genres and profit
ggplot(movies_and_genres, aes(genre, gross, fill = genre)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(title = "Gross revenue of movies by genre", x = "", y = "Gross revenue") + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank()) + 
    scale_y_log10(breaks = c(1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("100", "10,000", "1 million", "100 millions", "1 billion"))

# Boxplot of genres and imdb score
ggplot(movies_and_genres, aes(genre, score, fill = genre)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(title = "IMDB score of movies by genre", x = "", y = "IMDB score") + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank()) +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

# Scatter plots of genres based on gross and imdb score
ggplot(movies_and_genres, aes(x = gross, y = score, colour = genre)) + 
  geom_jitter(alpha = 0.1) +
  scale_x_log10(breaks = c(1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                labels = c("100", "10,000", "1 million", "100 millions", "1 billion")) +
  labs(title = "Gross Revenue and IMDB score for different genres", x = "Gross Revenue", y = "IMDB Score") +
  facet_wrap(~ genre) +
  theme_few() + 
  theme(legend.position = "None")
```

# Plot Keywords

We display the keywords that appear in at least 40 movies.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
movies0 <- movies[movies$plot_keywords != "", ]
keywords <- c()
i <- 1
for (ins in movies0$plot_keywords){
    kw <- strsplit(ins, "[|]")
    if (length(kw) != 0){
        for (word in kw[[1]]){
            if (!(word %in% keywords)){
                keywords[i] <- word
                i = i + 1
            }
        }
    }
}
# Create a dataframe with logical values which 
# indiacte the keywords of each movie
movies0$plot_keywords <- strsplit(movies0$plot_keywords, "[|]")
keywords_idx <- movies0[, c("movie_title", "plot_keywords")]
i = 1
mat <- matrix(rep(0, (dim(movies0)[1] * length(keywords))), nrow = dim(movies0)[1])
for (word in keywords_idx$plot_keywords){
    idx <- which(keywords %in% word)
    mat[i, idx] <- 1
    i = i + 1
}
colnames(mat) <- keywords
movies_and_keywords <- data.frame(mat)

# Find how many movies belong in each keyword
sum <- rep(0, length(keywords))
for (i in 1:length(keywords)){
    sum[i] <- sum(movies_and_keywords[, i])
}
keywords_sum <- data.frame(keywords = factor(keywords), sum = sum)
keywords_sum <- keywords_sum[order(sum, decreasing = FALSE),]
keywords_sum$keywords <- factor(keywords_sum$keywords, levels = keywords_sum$keywords)
keywords_sum <- keywords_sum[keywords_sum$sum > 39, ]

# Number of most popular keywords
ggplot(keywords_sum, aes(x = keywords, y = sum, fill = keywords)) + 
    geom_bar(stat = "identity", colour = "black") + 
    coord_flip() +
    labs(title = "Number of movies by keyword", x = "", y = "") + 
    geom_text(aes(label = sum), hjust = -0.2, vjust = 0.4) + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.text.x=element_blank(), axis.ticks.x = element_blank(), axis.ticks.y = element_blank()) 

######################### Create an appropriate dataframe with gross, imdb_score and keywords    for each movie
movies_and_keywords <- cbind(gross = movies0$gross, score = movies0$imdb_score, movies_and_keywords, stringsAsFactors = FALSE)
movies_and_keywords <- melt(movies_and_keywords, id = c("gross", "score"))
movies_and_keywords <- movies_and_keywords[movies_and_keywords$value == 1, ] 
movies_and_keywords$value <- NULL
colnames(movies_and_keywords) <- c("gross", "score", "keywords")
movies_and_keywords$keywords <- factor(movies_and_keywords$keywords, levels = keywords_sum$keywords)
movies_and_keywords <- movies_and_keywords[complete.cases(movies_and_keywords), ]

# Boxplot of genres and profit
ggplot(movies_and_keywords, aes(keywords, gross, fill = keywords)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(title = "Gross revenue of movies by keyword", x = "", y = "Gross revenue") + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank()) + 
    scale_y_log10(breaks = c(1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("100", "10,000", "1 million", "100 millions", "1 billion"))

# Boxplot of genres and imdb score
ggplot(movies_and_keywords, aes(keywords, score, fill = keywords)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(title = "IMDB score of movies by keyword", x = "", y = "IMDB score") + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank()) +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

# Scatter plots of keywords based on gross and imdb score
ggplot(movies_and_keywords, aes(x = gross, y = score, colour = keywords)) + 
  geom_jitter(alpha = 0.1) +
  scale_x_log10(breaks = c(1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                labels = c("100", "10,000", "1 million", "100 millions", "1 billion")) +
  labs(title = "Gross Revenue and IMDB score for different genres", x = "Gross Revenue", y = "IMDB Score") +
  facet_wrap(~ keywords) +
  theme_few() + 
  theme(legend.position = "None")
```

### Steven

###Louise
*Siow Meng comment: plyr library has been added at the first section of the document. Shall we all load the libraries in the first section?*
*Louise comment - yes I think that makes sense :) removed from here*

*Siow Meng comment: Encountered the following warning while knitting: Scale for 'y' is already present. Adding another scale for 'y', which will replace the existing scale.* 
*Yes, this is because I like my graphs to start at actual 0 rather than the ggplot default where they start at -0.5 and so have some padding - happy to discuss aesthetics when we consolidate plot themes*.

*Would potentially like to do some plots reg. directors - testing pushing again*
```{r echo = FALSE, message = FALSE}
##create summary statistics for average imdb score & number of movies for each director
directorssummary <- ddply(movies, ~ director_name,summarise,score_average=round(mean(imdb_score),2), gross_average=round(mean(gross),2), number_of_movies=length(director_name))
##sort by # of movies then imdb average score
sorteddirectorsummary <- arrange(directorssummary,desc(number_of_movies), desc(score_average))
##ensure that factors are in the order of number of movies, otherwise ggplot will default to alphabetical ordering in the graph
sorteddirectorsummary$director_name <- factor(sorteddirectorsummary$director_name, levels = sorteddirectorsummary$director_name[order(sorteddirectorsummary$number_of_movies)])

##plot for top 20 directors
ggplot(sorteddirectorsummary[1:20,], aes(x=director_name, y=number_of_movies, fill=director_name)) + geom_bar(stat="identity") + coord_flip() + guides(fill=FALSE) + scale_y_continuous(expand = c(0, 0)) + labs(x = "", y="Number of movies in sample") + ggtitle("Top 20 directors with multiple IMDB top 5000 movies") +  scale_y_continuous(expand = c(0,0)) +  expand_limits(y = c(0,1.05 * max(sorteddirectorsummary$number_of_movies)))
```

# Inferential Data Analysis

*For now, each have a section with one comparison and test/set of tests (t.test, var.test, cor.test etc.), it is expected this section will also include plots, later we can discuss how this flows into a narrative - we should let everyone in the slack group know what we're doing so that we don't overlap unecessarily*

*It is expected that these will be related to how inputs are correlated with the two outcome variables (gross and imdb_score)*

### Siow Meng

```{r echo=FALSE}
# boxplot of English & Non-English movies
temp <- movies

temp$english <- factor(temp$language == "English", levels = c(TRUE, FALSE), labels = c("English", "Non-English"))

ggplot(data = temp, aes(x = english, y = gross)) + geom_boxplot() + labs(title = "Gross Revenue of English and non-English Movies", x = "English or Non-English Movies", y = "Gross Revenue") + coord_cartesian(ylim = c(0, 1e8))

t.test(movies$gross[movies$language == "English"], movies$gross[movies$language != "English"], alternative = "greater")

var.test(movies$gross[movies$language == "English"], movies$gross[movies$language != "English"], alternative = "greater")

```

From the above box-and-whisker plots, we can observe a great difference between the revenues achieved by English and non-English movies. More than 75% of the non-English movies achieved gross revenue of US$10 million or lower. In contrast, more than half of the English movies have more than US$25 million revenues.

In addition, the gross revenues of English movies vary greatly (compared to non-English movies).

We are confident to say that the English movies in this dataset are generally more popular than non-English movies.

### Nikhita

### Cecilia

*Will do analysis on budget vs imdb score and gross*

### George

### Steven

### Louise

```{r echo=FALSE, message=FALSE}
##plot for imdb rating vs score
ggplot(sorteddirectorsummary, aes(x = number_of_movies, y = score_average)) + 
  geom_jitter(alpha = 0.2, width = 0.05) + geom_smooth() +
  labs(x = "Number of movies in sample", y = "Average IMDb Score")
```

```{r echo=FALSE, message=FALSE}
##plot for imdb rating vs score
## to do - sort out the axes
ggplot(sorteddirectorsummary, aes(x = number_of_movies, y = gross_average)) + 
  geom_jitter(alpha = 0.2, width = 0.05) + geom_smooth() +
  labs(x = "Number of movies in sample", y = "Average Gross Revenue")
```

```{r echo=FALSE}
##cor test for imdb rating vs # of movies
cor.test(sorteddirectorsummary$score_average,sorteddirectorsummary$number_of_movies)
##does seem like very loosely positively correlated and is probably because of the correlation with budget- more analysis to come.
##cor test for gross score vs # of movies
cor.test(sorteddirectorsummary$gross_average,sorteddirectorsummary$number_of_movies)
##does seem like somewhat positively correlated - although we can see from the graph that this doesn't seem linear.
```

*Would potentially like to do some inference regarding directors*

# Predictive Data Analysis

###Model Building and Justification
*we will all make two predictive models, one for "gross" and one for "imdb_score", using whatever inputs we can get from our dataset, at a later stage we'll compare them and see whose has the lowest mean squared error (which we can also justify) - and include that into this section*

*We discussed potentially including a new variable into the model, or to build a dual model that has different inputs for movies before 2010, and after 2010, which is the cutover point at which facebook likes for a movie became a meaningful indicator*

```{r echo=FALSE}

sort(names(movies))

model1 <- lm(gross ~ budget, data = movies)
summary(model1)
ggplot(data = movies, aes(x = budget, y = gross)) + geom_point() + geom_smooth(method = "lm") + coord_cartesian(xlim = c(0, 3e8))

model2 <- lm(gross ~ budget + movie_facebook_likes + cast_total_facebook_likes + director_facebook_likes + imdb_score + country, data = movies)
summary(model2)

model3 <- lm(gross ~ budget, data = movies[movies$title_year >= 2010, ])
summary(model3)
ggplot(data = movies[movies$title_year >= 2010, ], aes(x = budget, y = gross)) + geom_point() + geom_smooth(method = "lm") + coord_cartesian(xlim = c(0, 3e8))

model4 <- lm(gross ~ budget + movie_facebook_likes + cast_total_facebook_likes + director_facebook_likes + imdb_score + country, data = movies[movies$title_year >= 2010, ])
summary(model4)

```


###Model Performance
*we will then test this model using the test dataset, make a plot of the predictions against the actual values, and calculate the MSE/other success statistics*

#Conclusion
*to be completed after our analysis*

#To be removed- Notes and comments:

At the end of the assignment we should go back to:

* Check coding standards are consistent (and align with his recommendation - http://adv-r.had.co.nz/Style.html)
* Check language is consistent (tense / case)
* Convert ggplots into the same theme - colour scheme, fonts, etc.
* All assumptions have been noted in the appropriate sections
* We think we're roughly aiming for 20ish pages - tbd at a later stage
* Make sure we don't use language that implies causation when we can only infer correlation
* Double check each others' analyses for Simpson's paradox.
* Maybe put all libraries at the top?
