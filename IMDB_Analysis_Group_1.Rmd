---
title: "Analysis of IMDB Movie Dataset"
output: html_document
date: "16 October 2016"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(ggplot2)
library(ggthemes)
library(ggrepel)
library(reshape2)
library(dplyr)
library(plyr)
library(caret)
library(scales)
library(countrycode)
library(GGally)
library(knitr)
library(scales)
library(gridExtra)
library(pander)
```

#Executive Summary
*to be filled out after we have finished our analysis*

#Introduction

With the advent of big data and advanced predictive analytics capabilities, very often, producers are trying to determine beforehand what will make a movie successful or fail. Rather than relying on intuition and guesswork, producers such as Netflix are trying to figure out what will make a movie a successful one by analysing historical data available in the movie industry and increase their success rates through the use of data analytics. For Netflix, the recent award-winning drama 'House of Cards' was a success story of theirs - descriptive, prescriptive and predictive analytics were crucial in the process of developing the drama, to gauge what content viewers were interested in.

Similarly, a question which can be posed - whether one can predict the successfulness of a movie before it is released on cinema. To address this question, we have obtained a dataset from Kaggle scraped from the *imdb.com* containing 28 different variables for our analysis. Our key objectives for this report is to determine what makes a movie popular (based on gross revenue), and what makes a movie highly rated by the public (based on IMDB score). Descriptive analyses and influential analyses to look at which of the variables available in the dataset affect user ratings and gross revenue, will be followed by an attempt to develop a predictive model. This predictive model will try to determine which movies will be successful based on the relevant variable identified. 10% of the original data has been set aside to act as the test dataset and the model will be evaluated on its accuracy to predict gross revenue using Mean Squared Error and other success statistics.


#Methods

##Dataset

```{r, echo = FALSE}
movies <- read.csv(file = "movie_metadata.csv", header = TRUE, stringsAsFactors = FALSE, strip.white = TRUE)
```

The dataset used in this report was downloaded from *kaggle.com*, a website for data analysis competitions. The data was scraped from three websites using *Scrapy*, a Python library. The first website, *the-numbers.com*, is a website providing movie industry data. This website was used to scrape 5000 movie names along relevant data such as budget and gross domestic revenue. No pattern could be identified as to how the movie names were chosen. It was therefore assumed that the data represents a random sample. The scraped movie names were then matched with *imdb.com*, a popular resource for movie and TV-show ratings, and celebrity content, in order to get movie scores, direct links to movie pages, and other relevant features. All the movie and actor names were later aggregated and used to extract the number of Facebook likes on their respective official Facebook page. Finally, a face detection algorithm was applied to all movie posters to extract the number of faces in each poster. The dataset contains `r dim(movies)[1]` movies with `r dim(movies)[2]` variables spanning 100 years and 66 countries of origin.    

Although *imdb.com* covers movies from various different countries, the website is only offered in English, which implies certain limitations. The movies included in the dataset are skewed towards an English-speaking audience. This means that movies from North America, the UK, and other English speaking countries are overrepresented. In addition, the dataset includes more movies with release dates after 1980. In fact, multiple release years prior to 1980 include as little as one movie.
   
Despite these limitations the dataset offers extensive information on movies as well as a large enough number of observations. This will allow the analysis to  reveal interesting insights and answer the report's leading question. The dataset can be retrieved [here](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset).

The dataset includes the following variables:
```{r echo = FALSE}
# make table with column names and explanations

# create new df with column names ar rows
movie_variables <- colnames(movies)
movie_variables <- data.frame(sort(movie_variables))
# rename fisrt column
colnames(movie_variables) <- ("Variable Name")

actor_1_facebook_likes <- "Number of likes on main actor's Facebook page."
actor_1_name <- "Main actor's name."
actor_2_facebook_likes <- "Number of likes on first supporting actor's Facebook page."
actor_2_name <- "First supporting actor's name."
actor_3_facebook_likes <- "Number of likes on second supporting actor's Facebook page."
actor_3_name <- "Second supporting actor's name."
aspect_ratio <- "Aspect ratio the movie was shot in."
budget <- "Budget in USD. All budget's are estimates based on press reports."
cast_total_facebook_likes <- "Total number of likes of all actor Facebook pages."
color <- "Describes whether the movie was shot in color or black and white"
content_rating <- "Rating of suitability of movie for audience."
country <- "Country the movie was shot in. If the movie was shot in more than one country only the first country appearing was chosen. Throughout the analysis this variable will serve as proxy for the country of origin."
director_facebook_likes <- "Number of likes on director's Facebook page."
director_name <- "Name of director."
duration <- "Movie length in minutes."
facenumber_in_poster <- "Number of faces on movie poster."
genres <- "Movie genre."
gross <- "Latest domestic gross revenue reported on the-number.com, in USD."
imdb_score <- "Score voted by IMDB users, from 1 to 10 (highest)."
language <- "Language in which movie was shot."
movie_facebook_likes <- "Number of likes on movie's official Facebook page."
movie_imdb_link <- "Link to movie page."
movie_title <- "Movie name."
num_critic_for_reviews <- "Number of critics that wrote a review."
num_user_for_reviews <- "Number of imdb users that wrote a review."
num_voted_users <- "Number of imdb users that gave a rating."
plot_keywords <- "Keywords describing the movie plot."
title_year <- "Movie release year."

# initiate new column for explanations
movie_variables$Explanation <- c(actor_1_facebook_likes,
                                 actor_1_name,
                                 actor_2_facebook_likes,
                                 actor_2_name,
                                 actor_3_facebook_likes,
                                 actor_3_name,
                                 aspect_ratio,
                                 budget,
                                 cast_total_facebook_likes,
                                 color,
                                 content_rating,
                                 country,
                                 director_facebook_likes,
                                 director_name,
                                 duration,
                                 facenumber_in_poster,
                                 genres,
                                 gross,
                                 imdb_score,
                                 language,
                                 movie_facebook_likes,
                                 movie_imdb_link,
                                 movie_title,
                                 num_critic_for_reviews,
                                 num_user_for_reviews,
                                 num_voted_users,
                                 plot_keywords,
                                 title_year)

# create table
kable(movie_variables, format = "markdown")
```

## Data Cleansing

An initial review of our dataset identified a few key issues to be addressed before progressing with the analysis:

* The existence of missing values in key variables
* The inclusion of columns unnecessary to our analysis
* The inclusion of erroneous special characters that may be an artefact of text format conversion
* The inclusion of leading and trailing white spaces.

The below table shows the columns with missing values:

```{r, echo = FALSE}
    ## function to calculate list of NAs within a column
colNA <- function(dfCol){ sum(is.na(dfCol)) }
## To show table of sum of NAs by column
na_values <- data.frame(colnames(movies), apply(movies, 2, colNA))
na_values <- na_values[na_values$apply.movies..2..colNA.>0,]
colnames(na_values) <- c("Variable Name", "Number of missing values")
na_values <- na_values[order(na_values[, "Variable Name"]), ]
kable(na_values, format = "markdown", align = "l", row.names = FALSE)
```

To resolve these issues, the following cleansing process is applied:

* All rows where the title year has a missing value are removed - as there are a high number, and this variable is not expected to be key to the analysis.
* All rows where gross has a missing value are removed - as there are a high number, and this variable is expected to be one of the output variables
* All rows where the budget has a missing value are removed - as there are a high number, and this variable is expected to be key to the analysis.
* The aspect ratio column has a missing value removed - as there are a high number of NAs, and this variable is not expected to be key to the analysis. 
* The IMDB link column is removed - as this variable is not expected to be key to the analysis
```{r, echo = FALSE}
## To remove rows where NAs are present for any of the applicable columns
movies <- movies[complete.cases(movies[c("title_year","budget","gross")]),]
## To remove aspect ratio and imdb link columns
movies$aspect_ratio<- NULL
movies$movie_imdb_link<- NULL
```
* After this step there are only `r sum(is.na(movies))` remaining missing values within the dataframe. For these missing values, the mean value for that column will be used to replace all misisng values within that column. Although this has some drawbacks in terms of accuracy, it allows us to maintain rows of data with other valid information, and is an unbiased approach.
```{r, echo = FALSE}
## for loop to replace NAs with means for particular columns
for (i in c("actor_1_facebook_likes" , "actor_2_facebook_likes" , "actor_3_facebook_likes" , "num_critic_for_reviews" , "duration" , "facenumber_in_poster")){
    k <- which(colnames(movies) == i)
    movies[k][is.na(movies[k] == TRUE)] <- round(mean(movies[[k]], na.rm = TRUE), 0)
}
```

* Unwanted strings "Â" as well as leading and trailing white spaces are removed from the "title" column.

```{r, echo = FALSE}
movies <- movies[!duplicated(movies$movie_title),]
# Function to remove Â, leading and trailing whitespace from movies$movie_title
movie_title_processing <- function(str){
  str <- sub(pattern = "Â", replacement = "", str)
  str <- sub(pattern = "^\\s+|\\s+$", replacement ="", str)
}
# Apply previous function
movies$movie_title <- sapply(movies$movie_title, FUN = movie_title_processing)
```

Although some of these steps reduce the sample size for analysis, the rows removed would either cause later analysis to fail, cause the dataset to be inconsistent across various pieces of analysis, or produce misleading results.

This cleansed dataset (of `r nrow(movies)` rows) contains no NA values and is used for the remainder of the analysis. The head of the data frame is printed here:

*\@George, I agree with your comment to include the head, I have also included the scipen option below so that the budget does not show in scientific notation, but please let me know if you think this makes it look messier*

```{r, echo = FALSE, message = FALSE}
set.seed(1)
options(scipen=10000000)
intrain <- createDataPartition(y = movies[[1]], p = 0.9, list = FALSE)
train <- movies[intrain, ]
test <- movies[-intrain, ]
kable(t(movies[1:3, ]), format = "markdown", row.names = TRUE)
```

10% of the cleansed dataset (`r nrow(test)`) is then set aside to be the "test" dataset, leaving the remaining 90%  of our dataset (`r nrow(movies)`) as the training dataset. The training dataset alone will be used for all descriptive, inferential and predictive analysis, including model building. The "test" dataset will be used at a later stage to check the accuracy of the predicted model.

#Theory

# Analysis

##Descriptive Data Analysis

An initial correlation plot of all numerical variables displays the relationships between the variables in the dataset:

```{r, echo = FALSE, fig.width = 6, fig.align = "center"}
##extract only the numerical variables
moviesnumeric<- movies[c("duration", "title_year", "budget", "imdb_score", "movie_facebook_likes", "actor_1_facebook_likes", "actor_2_facebook_likes", "actor_3_facebook_likes", "cast_total_facebook_likes", "director_facebook_likes", "num_user_for_reviews", "num_critic_for_reviews", "facenumber_in_poster", "gross")]
## provide meaningful names to variables
labels_values <- rev(c("Gross", "# of faces in poster", "# of critics for reviews", "# of users for reviews", "Director FB likes",
                   "Total cast FB likes", "Actor 3 FB likes", "Actor 2 FB likes", "Actor 1 FB likes", "Movie FB likes",
                   "IMDB Score", "Budget", "Year of title", "Duration"))
##create correlation matrix
corrmatrix <- round(cor(moviesnumeric), 2)
meltedmovies<- melt(corrmatrix)

ggplot(data = meltedmovies, aes(x = Var1, y = Var2, fill = value)) + 
    geom_tile() + 
    labs(x = "", y = "", title = "Correlation Matrix") +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_x_discrete(labels = labels_values) + 
    scale_y_discrete(labels = labels_values) + 
    theme(axis.ticks.x = element_blank(), axis.ticks.y = element_blank(), panel.border = element_blank(),
          axis.title.x = element_blank(), axis.title.y = element_blank())  +
    scale_fill_gradient2(low = "#ce1254", mid="#1C3A54", high = "#5BB2F5", midpoint = 0, limit = c(-1,1), space = "Lab", name="Pearson\nCorrelation")
```

A large proportion of the numerical varibles available are relating to the facebook likes of various entities. In theory, these variables are likely to be most relevant to the performance of movies only after the usage of Facebook was widespread for marketing and celebrities. The below correlation matrices show the different interelationship of variables following the facebook area (post 2005), and following the era where facebook was widely used for marketing and celebrities (post 2010):

```{r echo=FALSE, fig.width = 10, fig.align = "center"}
# Correlation plot for movies after 2005
corrmatrix2005 <- round(cor(moviesnumeric[moviesnumeric$title_year >= 2005, ], use="pairwise.complete.obs"), 2)
meltedmovies2005 <- melt(corrmatrix2005)

post2005plot <- ggplot(data = meltedmovies2005, aes(x = Var1, y = Var2, fill = value)) + 
    geom_tile() + 
    labs(x = "", y = "", title = "Correlation Matrix\n(Movies after 2005)") +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    scale_x_discrete(labels = labels_values) + scale_y_discrete(labels = labels_values) +
    theme(axis.ticks.x = element_blank(), axis.ticks.y = element_blank(), panel.border = element_blank(),
          axis.title.x = element_blank(), axis.title.y = element_blank(), legend.position="none") +
    scale_fill_gradient2(low = "#ce1254", mid="#1C3A54", high = "#5BB2F5", midpoint = 0, limit = c(-1,1), space = "Lab", name="")  
    
# Correlation plot for movies after 2010
corrmatrix2010 <- round(cor(moviesnumeric[moviesnumeric$title_year >= 2010, ], use="pairwise.complete.obs"), 2)
meltedmovies2010 <- melt(corrmatrix2010)

post2010plot <- ggplot(data = meltedmovies2010, aes(x=Var1, y=Var2, fill=value)) +
    geom_tile() + 
    labs(x = "", y = "", title = "Correlation Matrix\n(Movies after 2010)") +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_x_discrete(labels = labels_values) + scale_y_discrete(labels = labels_values) +
    theme(axis.ticks.x = element_blank(), axis.ticks.y = element_blank(), panel.border = element_blank(),
          axis.title.x = element_blank(), axis.title.y = element_blank()) +
    scale_fill_gradient2(low = "#ce1254", mid="#1C3A54", high = "#5BB2F5", midpoint = 0, limit = c(-1,1), space = "Lab", name="")

##joint plot
grid.arrange(post2005plot, post2010plot, widths=c(2,2.4), ncol=2)
```

The descriptive analysis below focuses on individual variables and relationships in turn, drawing both from the above correlations, and from relationships between numerican and non-numerical variables.

### Language 

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
revYear <- ddply(movies, ~ title_year, summarise, meanRev = mean(gross, na.rm = TRUE))

ggplot(data = revYear, aes(x = title_year, y = meanRev)) + 
    geom_line(size = 1) + 
    theme_bw() + 
    labs(title = "Average Gross Revenue from Year 1920 to 2016", x = "Year", y = "Average Gross Revenue") + 
    scale_x_continuous(breaks = seq(1920, 2016, 8), limits = c(1920, 2016)) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10),
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "lr", colour = "gray") 

revLanguage <- ddply(movies, ~ title_year + language, summarise, meanRev = mean(gross, na.rm = TRUE))

ggplot(data = revLanguage[revLanguage$language == "English", ], aes(x = title_year, y = meanRev)) + 
    geom_line(size = 1) + 
    theme_bw() + 
    labs(title = "Average Gross Revenue of English Movies from Year 1920 to 2016", x = "Year", y = "Average Gross Revenue") + 
    scale_x_continuous(breaks = seq(1920, 2016, 8), limits = c(1920, 2016)) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10),
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "lr", colour = "gray") 

ggplot(data = revLanguage[revLanguage$language != "English", ], aes(x = title_year, y = meanRev)) + 
    geom_line(size = 1) + 
    theme_bw() + 
    labs(title = "Average Gross Revenue of Non-English Movies from Year 1920 to 2016", x = "Year", y = "Average Gross Revenue") + 
    scale_x_continuous(breaks = seq(1920, 2016, 8), limits = c(1920, 2016)) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10),
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "lr", colour = "gray") 
```

*Shall we keep only the one with the logarithmic scale? --George*

```{r GrossVSScore, echo = FALSE, fig.width = 10, fig.align = "center"}
temp <- movies
temp$us_or_others <- temp$country
temp$us_or_others[temp$country != "USA"] = "Non-USA"

ggplot(data = temp, aes(x = imdb_score, y = gross, colour = us_or_others)) + 
    geom_jitter(alpha = 0.1, width = 0.1) +
    theme_bw() +
    geom_smooth(method = "lm") + 
    labs(title = "Gross Revenue against IMDB Score for USA and non-USA Movies", x = "IMDB Score", y = "Gross Revenue") + 
    scale_colour_discrete(name = "Countries") +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10),
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    theme(legend.position = "None") +
    annotation_logticks(sides = "lr", colour = "gray") 
    
ggplot(data = temp, aes(x = imdb_score, y = gross, colour = us_or_others)) +
    geom_jitter(alpha = 0.1, width = 0.1) +
    geom_smooth(method = "lm") +
    theme_bw() +
    labs(title = "Gross Revenue against IMDB Score for USA and non-USA Movies", x = "IMDB Score", y = expression("Gross Revenue")) +
    scale_colour_discrete(name = "Countries") +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10),
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    facet_grid(~ us_or_others) +
    theme(legend.position = "None") +
    annotation_logticks(sides = "lr", colour = "gray")
```

### Country

Descriptive analysis on the country

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
# Sorting the movies by country and picking out the top 10
counted <- count(movies, 'country')
removednas <- counted[complete.cases(counted), ]
sorted <- arrange(removednas, desc(freq))
topcountries <- sorted[1:10, ]
topcountries$country <- factor(topcountries$country, levels = topcountries$country[order(topcountries$freq)])

# Taking the countries with more than 10 movies
countries <- subset(movies, country %in% c("Australia", "Canada", "China", "France", "Germany", "India", "Japan", "Spain", "UK", "USA"))

score <- countries$imdb_score
gross <- countries$gross

# Plot of gross revenue for the above countries
ggplot(countries, aes(country, gross, fill = country)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) + labs(title = "Gross revenue of movies by country", x = "", y = "Gross revenue") + theme_bw() + theme(legend.position = "None") + theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank()) + scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) 
    
# Plot of imdb score for the above countries
ggplot(countries, aes(country, score, fill = country)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) + labs(title = "IMDB Score of movies by country", x = "", y = "Gross revenue") + 
    labs(title = "IMDB Score of movies by country", x = "", y = "IMDB Score") + 
    theme_bw() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank()) +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) 


ggplot(countries, aes(x = score, y = gross, colour = country)) + 
  geom_jitter() + scale_x_log10() + labs(title = "IMDB Score and Gross Revenue for different countries", x = "IMDB Score", y = "Gross Revenue") +
  facet_wrap(~ country) +
  theme_few() + 
  theme(legend.position = "None") + 
    scale_y_log10(breaks = c(1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("100", "10,000", "1 million", "100 millions", "1 billion")) +
    geom_jitter(alpha = 0.2) + 
    labs(title = "IMDB Score and Gross Revenue for different countries", x = "IMDB Score", y = "Gross Revenue") +
    facet_wrap(~ country, nrow = 2) +
    theme_bw() + 
    theme(legend.position = "None") + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    annotation_logticks(sides = "lr", colour = "gray") 
```

More than 50% of US, UK and Germany releases are generating high revenues of over 10 million. On the other hand, more than 25% of releases in China and Spain are generating revenues of lower than 1 million.

Looking at the IMDB scores, movies across all ten countries have a mean score between 6 and 7. In India & Japan, at least 40% of the movies scored more than 7, whereas movies in Australia and USA have almost equal numbers scoring between 6 and 7.

Therefore, it can be deduced that revenue and IMDB scores are clearly independent of each other. This can be seen in the scatterplots - UK & US movies seem to be symmetrically about 'y = x'; however, the other countries show no particular relationship between the two variables.

### Budget

Descriptive analysis on the budget

1. Budget of movies

2. Budget of films in the top 13 countries (with 10 or more movies in the data set, the rest have been omitted)

```{r, echo = FALSE, message = FALSE, fig.width = 10, fig.align = "center"}
##Histogram for movie budget
ggplot(data = movies, aes(x = budget)) + 
    geom_histogram(fill = "#FF9999", colour = "black") + 
    theme_bw() +
    scale_x_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) + 
    labs(x = "Budget (USD)", y = "Count", title = "Budget of Movies") +
    annotation_logticks(sides = "tb", colour = "gray") 

#movieswithinrange <- count(movies$budget > 1000000 & movies$budget < 100000000)


##Country vs budget boxplot

#Find out which countries with over 10 movies in data set
subsetcountry <- count(movies, vars = "country") 
subsetcountry <- subsetcountry[order(subsetcountry[,2], decreasing = FALSE),] 
subsetcountry$country <- factor(subsetcountry$country, levels = subsetcountry$country)
subsetcountry <- subsetcountry[subsetcountry[,2] >= 10,]

ggplot(data = subsetcountry, aes(x = country, y = freq, fill = country)) + 
    geom_bar(stat = "identity", colour = "black") +
    coord_flip() +
    labs(title = "Number of movies by country", x = "", y = "") + 
    geom_text(aes(label = freq), hjust = -0.2, vjust = 0.4) + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),
          axis.title.x = element_blank(), axis.title.y = element_blank()) 

#Create dataframe with just Australia, Canada, China, France, Germany, Hong Kong, India, Italy, Japan, Mexico, Spain, UK, USA
budgetcountry <- subset(movies, country %in% c("Australia", "Canada", "China", "France", "Germany", "Hong Kong", "India", "Italy", "Japan", "Mexico", "Spain", "UK", "USA"))
budgetcountry <- subset(movies, country %in% subsetcountry$country)
budgetcountry$country <- factor(budgetcountry$country, levels = subsetcountry$country, ordered = TRUE)

#box plot for countries vs budget

ggplot(data = budgetcountry) + 
    geom_boxplot(aes(x = country, y = budget, fill = country)) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    theme_bw() +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank()) + 
    labs(x = "Country", y="Budget (USD)", title = "Budget of films by country") + 
    theme(legend.position="none") + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10))
```

From the histogram with count of movies across different budgets, we can see most movies are around the ballpark range of 1 million to 100 million, with around 85% of the movies falling under the range of 1 million to 100 million. A negative skew in the data can be observed. 

From the boxplots, we can see that the average budget on the films across different countries is similar, around a ballpark range of 10 million to 100 million. India, Mexico and Italy appears to have a lower average (???) for film budget than the rest of ther other countries.

### Genres and Plot Keywords

##### Genres

Descriptive analysis based on the movies genres and how do they correlate possibly with other variables of the dataset. Genres with less than 10 movies have been omitted. The first graph shows the number of movies in each genre while the second and the third plots present a boxplot for each genre associated with the profit of the movies and the IMDB score of the movies respectively.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
genres <- c()
i <- 1
for (ins in movies$genres){
    g <- strsplit(ins, "[|]")
    for (gnr in g[[1]]){
        if (!(gnr %in% genres)){
            genres[i] <- gnr
            i = i + 1
        }
    }
}
# Create a dataframe with logical values which 
# indiacte the categories of each movie
movies$genres <- strsplit(movies$genres, "[|]")
genres_idx <- movies[, c("movie_title", "genres")]
i = 1
mat <- matrix(rep(0, (dim(movies)[1] * length(genres))), nrow = dim(movies)[1])
for (g in genres_idx$genres){
    idx <- which(genres %in% g)
    mat[i, idx] <- 1
    i = i + 1
}
colnames(mat) <- genres
movies_and_genres <- data.frame(mat)

# Find how many movies belong in each genre
sum <- rep(0, length(genres))
for (i in 1:length(genres)){
    sum[i] <- sum(movies_and_genres[, i])
}
genres_sum <- data.frame(genre = factor(genres), sum = sum)
genres_sum <- genres_sum[order(sum, decreasing = FALSE),]
genres_sum$genre <- factor(genres_sum$genre, levels = genres_sum$genre)
genres_sum <- genres_sum[genres_sum$sum > 10, ]

# Number of movies belonging to each genre
ggplot(genres_sum, aes(x = genre, y = sum, fill = genre)) + 
    geom_bar(stat = "identity", colour = "black") + 
    coord_flip() +
    labs(title = "Number of movies by genre", x = "", y = "") + 
    geom_text(aes(label = sum), hjust = -0.2, vjust = 0.4) + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),
          axis.title.x = element_blank(), axis.title.y = element_blank()) 

## Create an appropriate dataframe with gross, imdb_score and genres for each movie
movies_and_genres <- cbind(gross = movies$gross, score = movies$imdb_score, movie_title = movies$movie_title, movies_and_genres, stringsAsFactors = FALSE)
## saving a full wide data frame to be used in later analysis
movies_and_genres_wide <- movies_and_genres
movies_and_genres <- melt(movies_and_genres, id = c("gross", "score", "movie_title"))
movies_and_genres$variable <- gsub("[.]", " ", movies_and_genres$variable)
movies_and_genres <- movies_and_genres[movies_and_genres$value == 1, ] 
movies_and_genres$value <- NULL
colnames(movies_and_genres) <- c("gross", "score", "movie_title", "genre")
movies_and_genres$genre <- factor(movies_and_genres$genre, levels = genres_sum$genre)
movies_and_genres <- movies_and_genres[complete.cases(movies_and_genres), ]

# Boxplot of genres and profit
ggplot(movies_and_genres, aes(genre, gross, fill = genre)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    coord_flip() +
    labs(title = "Gross revenue of movies by genre", x = "", y = "Gross revenue") + 
    theme_bw() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank()) + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10))

# Boxplot of genres and imdb score
ggplot(movies_and_genres, aes(genre, score, fill = genre)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    coord_flip() +
    labs(title = "IMDB score of movies by genre", x = "", y = "IMDB score") + 
    theme_bw() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank()) +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10))

# Scatter plots of genres based on gross and imdb score
ggplot(movies_and_genres, aes(x = score, y = gross, colour = genre)) + 
    geom_jitter(alpha = 0.1) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    labs(title = "Gross Revenue and IMDB score for different genres", x = "Gross Revenue", y = "IMDB Score") +
    facet_wrap(~ genre) +
    theme_bw() + 
    theme(legend.position = "None") +
    annotation_logticks(sides = "lr", colour = "gray") 
```

#### Plot Keywords

We display the 20 most popular keywords.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
movies0 <- movies[movies$plot_keywords != "", ]
keywords <- c()
i <- 1
for (ins in movies0$plot_keywords){
    kw <- strsplit(ins, "[|]")
    if (length(kw) != 0){
        for (word in kw[[1]]){
            if (!(word %in% keywords)){
                keywords[i] <- word
                i = i + 1
            }
        }
    }
}
# Create a dataframe with logical values which 
# indiacte the keywords of each movie
movies0$plot_keywords <- strsplit(movies0$plot_keywords, "[|]")
keywords_idx <- movies0[, c("movie_title", "plot_keywords")]
i = 1
mat <- matrix(rep(0, (dim(movies0)[1] * length(keywords))), nrow = dim(movies0)[1])
for (word in keywords_idx$plot_keywords){
    idx <- which(keywords %in% word)
    mat[i, idx] <- 1
    i = i + 1
}
colnames(mat) <- keywords
movies_and_keywords <- data.frame(mat)

# Find how many movies belong in each keyword
sum <- rep(0, length(keywords))
for (i in 1:length(keywords)){
    sum[i] <- sum(movies_and_keywords[, i])
}
keywords_sum <- data.frame(keywords = factor(keywords), sum = sum)
keywords_sum <- keywords_sum[order(sum, decreasing = FALSE),]
keywords_sum$keywords <- factor(keywords_sum$keywords, levels = keywords_sum$keywords)
#keywords_sum <- keywords_sum[keywords_sum$sum > 39, ]
keywords_sum <- keywords_sum[(dim(keywords_sum)[1]-19):dim(keywords_sum)[1] ,]

# Number of most popular keywords
ggplot(keywords_sum, aes(x = keywords, y = sum, fill = keywords)) + 
    geom_bar(stat = "identity", colour = "black") + 
    coord_flip() +
    labs(title = "Number of movies by keyword", x = "", y = "") + 
    geom_text(aes(label = sum), hjust = -0.2, vjust = 0.4) + 
    theme_few() +
    theme(legend.position = "None") +
    theme(axis.text.x=element_blank(), axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),
          axis.title.x = element_blank(), axis.title.y = element_blank()) 

## Create an appropriate dataframe with gross, imdb_score and keywords    for each movie
movies_and_keywords <- cbind(gross = movies0$gross, score = movies0$imdb_score, movies_and_keywords, stringsAsFactors = FALSE)
movies_and_keywords <- melt(movies_and_keywords, id = c("gross", "score"))
movies_and_keywords$variable <- gsub("[.]", " ", movies_and_keywords$variable)
movies_and_keywords <- movies_and_keywords[movies_and_keywords$value == 1, ] 
movies_and_keywords$value <- NULL
colnames(movies_and_keywords) <- c("gross", "score", "keywords")
movies_and_keywords$keywords <- factor(movies_and_keywords$keywords, levels = keywords_sum$keywords)
movies_and_keywords <- movies_and_keywords[complete.cases(movies_and_keywords), ]

# Boxplot of genres and profit
ggplot(movies_and_keywords, aes(keywords, gross, fill = keywords)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    coord_flip() +
    labs(title = "Gross revenue of movies by keyword", x = "", y = "Gross revenue") + 
    theme_bw() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank()) + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10))

# Boxplot of genres and imdb score
ggplot(movies_and_keywords, aes(keywords, score, fill = keywords)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    coord_flip() +
    labs(title = "IMDB score of movies by keyword", x = "", y = "IMDB score") + 
    theme_bw() +
    theme(legend.position = "None") +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank()) +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10))

# Scatter plots of keywords based on gross and imdb score
ggplot(movies_and_keywords, aes(x = score, y = gross, colour = keywords)) + 
    geom_jitter(alpha = 0.2) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    labs(title = "Gross Revenue and IMDB score for different keywords", x = "Gross Revenue", y = "IMDB Score") +
    facet_wrap(~ keywords, nrow = 4) +
    theme_bw() + 
    theme(legend.position = "None") +
    annotation_logticks(sides = "lr", colour = "gray") 
```

### Gross revenue over time

This section will analyze the evolution of revenues over time.
```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
# plot gross vs. years
temp <- movies[!is.na(movies$title_year),]
ggplot(temp, aes(x = factor(title_year), y = gross, fill = factor(title_year))) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    theme_bw() + 
    theme(axis.text.x=element_text(angle = 45, hjust = 0.5, vjust = 0.5), legend.position = "None", axis.title.x = element_blank()) +
    labs(title = "Gross revenues against year, for years with >= 10 entries", x = "", y = "Gross Revenue") + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billion"), limits = c(1, 1e+10)) +
    scale_x_discrete(breaks = seq(1920, 2016, 2), labels = seq(1920, 2016, 2), drop = FALSE) +
    annotation_logticks(sides = "lr", colour = "gray") 

```

The above plot shows that there might be a slight upward trend in gross revenue over the years. Some years, however, include fewer than ten movies. To get a more accurate picture of the development of gross revenues over time the following two plots will only include years which have a minimum of ten entries.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
# plot all years that have at least ten movies
# table(movies$title_year)  
# shows that from 1980 onwards all the years have at least ten entries

# function to plot multiple plots at in one grid (from r-cookbook)

# subset movies data frame to include all movies from 1980 onwards
temp <- movies[movies$title_year >= 1980, ]
# plot the range of IMDB scores for all years
p1 <- ggplot(temp, aes(x = factor(title_year), y = gross, fill = factor(title_year))) + 
    geom_boxplot() +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5), legend.position = "None", axis.title.x = element_blank()) +
    labs(title = "Gross revenues against year, for years with >= 10 entries", x = "", y = "Gross Revenue") +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "1 billions"),  limits = c(1, 1e+10)) +
   annotation_logticks(sides = "lr", colour = "gray") 

lm_model2 <- lm(log10(gross) ~ title_year, data = temp)
# make a scatter plot that shows trend in IMDB scores
p2 <- ggplot(temp, aes(x = title_year, y = gross, colour = factor(title_year))) + 
    geom_jitter(alpha = 0.4) +
    geom_abline(intercept = lm_model2$coefficients[1], slope = lm_model2$coefficients[2], size = 1) +
    theme_bw() + 
    labs(x = "", y = "Gross Revenue") +
    theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5), legend.position = "None", axis.title.x = element_blank()) +
    scale_x_continuous(breaks = seq(min(temp$title_year), max(temp$title_year), by = 1), 0.5) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "lr", colour = "gray") 

grid.arrange(p1, p2, ncol=1)
```

The plots above give a less biased represenation of the development of gross revenues over time. The revenues now appear more constant. The trendline on the second plot indicates that there is a slight upward trend. Even though the 2000s have more extreme oultliers than the 1990s and 1980s these do not seem to have a substantial affect the median (mean) gross revenues.

```{r, echo = FALSE}
# create function that converts years into decades
# function left here because used by Louise
convert_decade <- function(year){
  low <- year - year %% 10
  high <- year - year %% 10 + 9
  paste(as.character(low), as.character(high), sep = "-")
}
# apply previous function
movies$decade <- sapply(movies$title_year, FUN = convert_decade)
```

###Directors

```{r echo = FALSE, message = FALSE}
##create summary statistics for average imdb score & number of movies for each director
directorssummary <- ddply(movies, ~ director_name,summarise,score_average=round(mean(imdb_score),2), gross_average=round(mean(gross),2), number_of_movies=length(director_name))
##sort by # of movies then imdb average score
sorteddirectorsummary <- arrange(directorssummary,desc(number_of_movies), desc(score_average))
##ensure that factors are in the order of number of movies, otherwise ggplot will default to alphabetical ordering in the graph
sorteddirectorsummary$director_name <- factor(sorteddirectorsummary$director_name, levels = sorteddirectorsummary$director_name[order(sorteddirectorsummary$number_of_movies)])
```


```{r in-text-fig, echo=FALSE,  fig.width = 3, fig.height=3, out.extra='style="float:right"'}
##Histogram for number of moveies per director
ggplot(sorteddirectorsummary, aes(x = number_of_movies)) + 
    geom_histogram(binwidth = 1, fill = "darkblue") + 
    theme_bw() +
    labs(x = "Number of movies\nper director", y = "Number of directors",
         title = "Density of number of \nmovies per director") +
    scale_x_continuous(breaks = c(0, 5, 10, 15, 20, 25, 30), limits = c(0, 30)) 
```

```{r echo=FALSE, fig.width = 10, fig.align = "center"}
##add a categorical variable for one movie or more
sorteddirectorsummary$more_than_one_movie <- rep.int(0, nrow(sorteddirectorsummary))
sorteddirectorsummary$more_than_one_movie[sorteddirectorsummary$number_of_movies > 1] <- 1
##calculate the percentage of directors with exactly one movie
dirpercentage <- round(100 * length(sorteddirectorsummary$number_of_movies[sorteddirectorsummary$number_of_movies == 1])
                       / length(sorteddirectorsummary$number_of_movies), 2)
```

\
Before looking into the relationship with the key output variable, gross revenue, descriptive statistics of the director data are explored. There are `r nrow(sorteddirectorsummary)` distinct directors in the data sample, the density of movies per director is shown on the figure on the right.

This is clearly positively skewed, with many directors having only 1 movie in the dataset, and only a few having significantly more. In fact, approximately  `r dirpercentage` of those directors have only 1 movie in the top 5000, leaving `r 100-dirpercentage` that have more than 1.

```{r echo=FALSE}
##add # of movies per director to the main dataset.
movieswithdirectordata <- merge(movies, sorteddirectorsummary, by = "director_name")
movieswithdirectordata <- rename(movieswithdirectordata, c('number_of_movies'='dir_number_of_movies'))
```


```{r echo=FALSE}
##function to create human readable axis labels.
##code taken from publically available github to give human readable axis labels. (https://github.com/fdryan/R/blob/master/ggplot2_formatter.r)
human_numbers <- function(x = NULL, smbl =""){
  humanity <- function(y){             
    
    if (!is.na(y)){
      
       b <- round_any(abs(y) / 1e9, 0.1)
       m <- round_any(abs(y) / 1e6, 0.1)
       k <- round_any(abs(y) / 1e3, 0.1)
      
      if ( y >= 0 ){ 
        y_is_positive <- ""
      } else {
        y_is_positive <- "-"
      }
      
      if ( k < 1 ) {
        paste0(y_is_positive, smbl, y )
        } else if ( m < 1){
        paste0 (y_is_positive, smbl,  k , "k")
      } else if (b < 1){
        paste0 (y_is_positive, smbl, m ,"m")
      } else {
        paste0 (y_is_positive, smbl,  comma(b), "b")     
      }
    }
  }
  
  sapply(x,humanity)
}

human_num <- function(x){human_numbers(x, smbl = "")} 
human_usd <- function(x){human_numbers(x, smbl = "$")}
```


```{r echo = FALSE, message = FALSE, fig.width = 3, fig.height = 2.5, fig.align = "center", out.extra='style="float:left"'}
##plot for gross revenue vs number of directors in sample
ggplot(movieswithdirectordata, aes(x = dir_number_of_movies, y = gross)) + 
    geom_jitter(alpha = 0.1, width = 1) +
    theme_bw() +
    labs(x = "Number of movies\nper director", y = "Gross Revenue") + 
    scale_y_continuous(label = human_usd) + 
    scale_x_continuous(breaks = c(0, 5, 10, 15, 20, 25, 30), limits = c(0, 30)) +
    geom_smooth()
##*Shall I convert the y-axis of the following graphs into log scale? I also set the limits of x-axis to [0, 30] and we miss 1 observation with x value >100. --George*##
```

An initial look at the relationship between the number of movies that the director has in the dataset, and the gross revenue of those movies does not show a clearly defined correlation, which can be seen in the figure on the left.


To check against one potential confounder for the relationship that number of movies per director has with gross, the correlation between movies per director and budget is calculated.

```{r echo=FALSE}
c <- cor.test(movieswithdirectordata$dir_number_of_movies, movieswithdirectordata$budget)
```

Even though this correlation was found to be statistically significant, with a p-value of `r c$p.value`, it is quite small (`r round(cor(movieswithdirectordata$dir_number_of_movies, movieswithdirectordata$budget),3)`%), so the analysis of movies by director sample on gross revenue can be continued without an obvious confounder of budget.

Focusing on the relationship between gross revenue and number of movies per director with the additional dimension of genres, there is an approximate pattern of a positive correlation up to 10 movies by director, and then a less predictable path for those with directors with higher numbers of movies.

```{r echo = FALSE}
movies_and_genres_withdirectordata <- merge(movies_and_genres, movieswithdirectordata[,c("movie_title","dir_number_of_movies")], by="movie_title")
```

```{r echo = FALSE, fig.width = 10, fig.align = "center", warning = FALSE, message = FALSE}
##requires the above
ggplot(movies_and_genres_withdirectordata, aes(x = dir_number_of_movies, y = gross, colour = genre)) + 
  geom_jitter(alpha = 0.1) + 
    scale_y_continuous(label=human_usd) + 
    labs(title = "Gross Revenue and # of director movies for different genres", x = "# of Movies by Director", 
         y = "Gross Revenue") + 
    facet_wrap(~ genre) + 
    theme(legend.position = "None") + geom_smooth(color="#000000")
```



```{r echo = FALSE, fig.width = 10, fig.align = "center"}
##add a categorical variable for ten movies or more
sorteddirectorsummary$more_than_ten_movies <- rep("Fewer than 10", nrow(sorteddirectorsummary))
sorteddirectorsummary$more_than_ten_movies[sorteddirectorsummary$number_of_movies>10] <- "10+"
##calculate the percentage of directors with  more than 10 movies
morethantendirpercentage <- round(100*length(sorteddirectorsummary$number_of_movies[sorteddirectorsummary$more_than_ten_movies=="10+"])/length(sorteddirectorsummary$number_of_movies),2)
##merge movie data with director data
movieswithdirectordata <- merge(movieswithdirectordata, sorteddirectorsummary[,c("director_name","more_than_ten_movies")], by="director_name")
##refactor so that fewer than 10 is before 10+
movieswithdirectordata$more_than_ten_movies <- factor(movieswithdirectordata$more_than_ten_movies, levels=c("Fewer than 10", "10+"))
##calculate the percentage of movies where the director has more than ten movies
morethantenmovpercentage <- round(100*length(movieswithdirectordata$more_than_ten_movies[movieswithdirectordata$more_than_ten_movies=="10+"])/length(movieswithdirectordata$more_than_ten_movies),2)
```
Only approximately `r morethantendirpercentage`% directors have more than ten movies, which, when considering movies, constitutes approximately `r morethantenmovpercentage`% of movies in our sample.

# Inferential Data Analysis

*For now, each have a section with one comparison and test/set of tests (t.test, var.test, cor.test etc.), it is expected this section will also include plots, later we can discuss how this flows into a narrative - we should let everyone in the slack group know what we're doing so that we don't overlap unecessarily*

*It is expected that these will be related to how inputs are correlated with the two outcome variables (gross and imdb_score)*

### Siow Meng

```{r echo = FALSE, results = TRUE, fig.width = 10, fig.align = "center"}
# boxplot of English & Non-English movies
temp <- movies

temp$english <- factor(temp$language == "English", levels = c(TRUE, FALSE), labels = c("English", "Non-English"))

ggplot(data = temp, aes(x = english, y = gross)) + geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) + labs(title = "Gross Revenue of English and non-English Movies", x = "English or Non-English Movies", y = "Gross Revenue") + coord_cartesian(ylim = c(0, 1e8))

ggplot(data = temp, aes(x = english, y = gross, fill = english)) + 
    theme_bw() +
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    labs(title = "Gross Revenue of English and non-English Movies", x = "", y = "Gross Revenue") +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "lr", colour = "gray") +
    theme(legend.position = "none", axis.ticks.x = element_blank(), panel.grid.major.x = element_blank(),
          axis.title.x = element_blank())

t.test(movies$gross[movies$language == "English"], movies$gross[movies$language != "English"], alternative = "greater")

var.test(movies$gross[movies$language == "English"], movies$gross[movies$language != "English"], alternative = "greater")
```

From the above box-and-whisker plots, we can observe a great difference between the revenues achieved by English and non-English movies. More than 75% of the non-English movies achieved gross revenue of US$10 million or lower. In contrast, more than half of the English movies have more than US$25 million revenues.

In addition, the gross revenues of English movies vary greatly (compared to non-English movies). The t-test and variance-test confirms these findings.

We are confident to say that the English movies in this dataset are generally more popular than non-English movies.

```{r echo = FALSE, results = TRUE, fig.width = 10, fig.align = "center"}
# boxplot of USA & Non-USA movies
temp$us_or_others <- temp$country
temp$us_or_others[temp$country != "USA"] <- "Non-USA"

#temp$english <- factor(temp$language == "English", levels = c(TRUE, FALSE), labels = c("English", "Non-English"))

ggplot(data = temp, aes(x = us_or_others, y = gross)) + geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) + labs(title = "Gross Revenue of USA and non-USA Movies", x = "USA or Non-USA Movies", y = "Gross Revenue") + coord_cartesian(ylim = c(0, 1e8))

ggplot(data = temp, aes(x = us_or_others, y = gross, fill = us_or_others)) + 
    theme_bw() +
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    labs(title = "Gross Revenue of USA and non-USA Movies", x = "", y = "Gross Revenue") +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "lr", colour = "gray") +
    theme(legend.position = "none", axis.ticks.x = element_blank(), panel.grid.major.x = element_blank(),
          axis.title.x = element_blank())

t.test(movies$gross[movies$country == "USA"], movies$gross[movies$country != "USA"], alternative = "greater")

var.test(movies$gross[movies$country == "USA"], movies$gross[movies$country != "USA"], alternative = "greater")
```

Similarly, we did a box-and-whisker plots of revenues achieved by USA and non-USA movies. Movies made in the USA have achieved more than 50 million USD in average revenue while non-USA movies have around 25 million USD

In addition, the gross revenues of USA movies vary greatly (compared to non-USA movies). The t-test and variance-test confirms these findings.

We are confident to say that the USA movies in this dataset are generally more popular than non-USA movies.


### Nikhita

Looking at the content rating for the movies


```{r echo=FALSE}
# Replacing M and GP with PG
movies$content_rating[movies$content_rating == "M"] <- "PG"
movies$content_rating[movies$content_rating == "GP"] <- "PG"

# Getting the top five ratings
ratingcounts <- count(movies, 'content_rating')
ratingsort <- arrange(ratingcounts, desc(freq))
topratings <- ratingsort[1:5,]

topratedmovies <- subset(movies, content_rating %in% c("PG-13", "R", "PG"))
contentrating <- topratedmovies$content_rating
contentscore <- topratedmovies$imdb_score
contentgross <- topratedmovies$gross

ggplot(topratedmovies, aes(contentrating, contentgross, fill = contentrating)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    labs(title = "Gross Revenue of movies by rating", x = "Content Rating", y = "Gross Revenue") +
    theme_bw() +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    theme(legend.position = "none", axis.ticks.x = element_blank(), panel.grid.major.x = element_blank()) +
    annotation_logticks(sides = "lr", colour = "gray") 

# Does the gross revenue vary with different ratings?
RvsPG13 <- t.test(movies$gross[movies$content_rating == "R"], movies$gross[movies$content_rating == "PG-13"])
pander(RvsPG13)

PG13vsPG <- t.test(movies$gross[movies$content_rating == "PG-13"], movies$gross[movies$content_rating == "PG"])
pander(PG13vsPG)

RvsPG <- t.test(movies$gross[movies$content_rating == "R"], movies$gross[movies$content_rating == "PG"])
pander(RvsPG)
```

PG, PG-13 and R are the most common ratings observed in our datatset. Looking the boxplots, R movies tend to on average have higher IMDB scores and lower revenues than PG or PG-13 rated movies. 

This is consistent with the t-test results. There is no difference in the gross revenue for PG and PG-13 movies whereas p-values lower than 5% support the alternative hypothesis that the difference in gross revenue for R and P/PG-13 movies is not equal to 0.

### Cecilia

We would like to investigate whether the imdb score of movie is affected by the budget for the particular movie.

```{r echo = FALSE, fig.width = 10, fig.align = "center"}
#scatter plot for budget vs imdb score
ggplot(data = movies, aes(y = budget, x = imdb_score)) + 
    geom_jitter(alpha = 0.4, colour = "#FF9999") + 
    theme_bw() +
    labs(y = "Budget", x = "IMDB Score", title = "Budget versus IMDB Score") + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10))+
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    annotation_logticks(sides = "lr", colour = "gray") 

#covariance test
cov(movies$budget, movies$imdb_score)

#correlation test
cor.test(movies$budget, movies$imdb_score)
```

The covariance value of 5.3x10^7 suggests that there is an upward trend - as budget increases, imdb score increases. The Pearson's correlation test between budget and IMDB score gives a p-value of 0.047, which suggests that there isn't a high correlation between budget of the movie and rating on IMDB. 

Even if we dig deeper to look at the effect of budget on IMDB score for movies from different countries, it appears to be that there is not much of a trend.

```{r echo = FALSE, fig.width = 10, fig.align = "center"}
ggplot(budgetcountry, aes(y = budget, x = imdb_score, colour = country)) + 
    geom_jitter(alpha = 0.2) + 
    labs(title = "Budget and IMDB score for different countries", y = "Budget", x = "IMDB Score") + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    facet_wrap(~ country) +
    theme_bw() + 
    theme(legend.position = "None") +
    annotation_logticks(sides = "lr", colour = "gray") 
```

```{r echo=FALSE}

ggplot(budgetcountry, aes(x = budget, y = imdb_score, colour = country)) + 
  geom_jitter() + scale_x_log10()+ labs(title = "Budget and IMDB score for different countries", x = "Budget", y = "IMDB Score") + scale_x_log10(breaks = c(1e+03, 1e+05, 1e+07, 1e+09), labels = c("1000", "100,000", "10 million", "1000 million")) +
  facet_wrap(~ country) +
  theme_bw() + 
  theme(legend.position = "None")

```


Next, we want to look to see whether the budget has an influence on gross revenue.

```{r echo = FALSE, fig.width = 10, fig.align = "center"}
#scatter plot for budget vs gross
ggplot(data = movies, aes(x = budget, y = gross)) + 
    geom_jitter(alpha = 0.2, colour = "#FF9999") + 
    theme_bw() + 
    labs(x = "Budget", y = "Gross Revenue", title = "Budget versus Gross Revenue") +
    scale_x_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "tlbr", colour = "gray") 

#covariance test
cov(movies$budget, movies$gross)

#correlation test
cor.test(movies$budget, movies$gross)
```

The covariance value of 1.6 x 10^15 suggests that there is an upward trend, as budget increases, revenue from the movie increases. The Pearson's correlation test between budget and gross gives us a value of 0.22, which suggests that there isn't a high correlation between budget of the movie and gross revenue, but higher than the correlation between budget and imdb score.

If we subset the data by different countries, we still do not see a huge correlation between budget versus gross revenue.

```{r echo = FALSE, fig.width = 10, fig.align = "center"}
ggplot(budgetcountry, aes(x = budget, y = gross, colour = country)) + 
    geom_jitter(alpha = 0.2) +  
    labs(title = "Budget and Gross Revenue for different countries", x = "Budget", y = "Gross Revenue") +       
    theme_bw() + 
    scale_x_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) +
    annotation_logticks(sides = "tlbr", colour = "gray") +
    facet_wrap(~ country) +
    theme(legend.position = "None")
```

As both variables are indicators of a movie's popularity, we can conclude from the above analysis that budget does not have a huge influence on how 'popular' a movie is.

Does budget affect gross profit margin?

```{r echo = FALSE, fig.width = 10, fig.align = "center"}
#create grossprofit column
movieswprofit <- data.frame(movies)
movieswprofit$grossprofitmargin <- (movieswprofit$gross - movieswprofit$budget)/movieswprofit$gross * 100

#scatter plot for budget vs gross profit margin 
ggplot(data = movieswprofit, aes(x = budget, y = grossprofitmargin)) + 
    geom_point(alpha = 0.4, colour = "#FF9999") + 
    theme_bw() +
    scale_x_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) + 
    scale_y_continuous(limits = c(-1000, 100)) + 
    labs(x = "Budget in USD", y = "Gross Profit Margin as %") +
    annotation_logticks(sides = "tb", colour = "gray") 

#covariance test
cov(movieswprofit$budget, movieswprofit$grossprofitmargin, use = "complete.obs") 

#correlation test
cor.test(movieswprofit$budget, movieswprofit$grossprofitmargin, use = "complete.obs")
```

Finally, we would also like to look at the effect of gross vs on gross profit margin, whether the an increase in budget would make a better movie, and hence a higher gross profit margin. Gross profit margin can be used as an indictor of profitability of movie. Based on the data, it appears that there is a negative correlation (-0.31) between budget and profit. Although it is not very strong, it still suggests that an increase in budget has a slight negative impact on gross profit margin.

From the plot, we can see that a lot of movies are not profitable. Around half of the movies are profitable (count = 1988), half are not (count = 1801).

```{r echo = FALSE, fig.width = 10, fig.align = "center"}
movieswprofit$profitable <- ifelse(movieswprofit$grossprofitmargin >= 0, "yes", "no")

table(movieswprofit$profitable)
```
From the analysis above, we can conclude there is a positive correlation between budget and imdb score, as well as gross revenue, though the correlation themselves are not strong.

### George

In case of nominal variables it doesn't make sense to talk about what happens if these variables increase/decrease, because they don't have a numerical value that can go up/down. So we can correlate neither "Genres" nor "Keywords" with "Gross Revenue" or "IMDB Score". However, there are measures of strength of association we can use that are somewhat analogous. 

*Genres analysis*

For gross revenue prediction.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
genres_model_gross <- lm(gross ~ genre, data = movies_and_genres)
summary(genres_model_gross)
intercept1 <- lm(movies_and_genres$gross ~ genres_model_gross$fitted)$coefficients[[1]]

movies_and_genres_full <- data.frame(movies_and_genres[,c("gross","score","genre")], predicted_gross = genres_model_gross$fitted)
avg_gross <- movies_and_genres_full[, 3:4]
avg_gross <- avg_gross[!duplicated(avg_gross$genre), ]
avg_gross <- avg_gross[order(avg_gross$predicted_gross), ]
rownames(avg_gross) <- 1:dim(avg_gross)[1]

ggplot() + 
    geom_point(aes(x = movies_and_genres_full$predicted_gross, y = movies_and_genres_full$gross, colour = movies_and_genres_full$genre), alpha = 0.1) + 
    geom_abline(intercept = intercept1) + 
    geom_point(aes(x = avg_gross$predicted_gross, y = avg_gross$predicted_gross, colour = avg_gross$genre), 
               size = 2, shape = 21, stroke = 2) + 
    geom_text(aes(x = avg_gross[seq(1, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   y = avg_gross[seq(1, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   label = avg_gross[seq(1, dim(avg_gross)[1], 2), ]$genre), 
               check_overlap = F, nudge_y = -0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    geom_text(aes(x = avg_gross[seq(2, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   y = avg_gross[seq(2, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   label = avg_gross[seq(2, dim(avg_gross)[1], 2), ]$genre), 
               check_overlap = F, nudge_y = 0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    scale_x_log10(breaks = c(2e+07, 4e+07, 6e+07, 8e+07, 1e+08), 
                  labels = c("20 millions", "40 millions", "60 millions", "80 millions", "100 millions")) + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) + 
    labs(title = "Gross Revenue for different genres", x = "Predicted Gross Revenue", y = "Observed Gross Revenue") +
    theme_bw() + 
    theme(legend.position = "None") +
    annotation_logticks(sides = "tlbr", colour = "gray") 
```

For IMDB score prediction.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
genres_model_score <- lm(score ~ genre, data = movies_and_genres)
summary(genres_model_score)
intercept2 <- lm(movies_and_genres$score ~ genres_model_score$fitted)$coefficients[[1]]

movies_and_genres_full <- data.frame(movies_and_genres[,c("gross","score","genre")], predicted_score = genres_model_score$fitted)
avg_score <- movies_and_genres_full[, 3:4]
avg_score <- avg_score[!duplicated(avg_score$genre), ]
avg_score <- avg_score[order(avg_score$predicted_score), ]
rownames(avg_score) <- 1:dim(avg_score)[1]

ggplot() + 
    geom_jitter(aes(x = movies_and_genres_full$predicted_score, y = movies_and_genres_full$score, colour = movies_and_genres_full$genre), alpha = 0.1) + 
    geom_abline(intercept = intercept2) + 
    geom_point(aes(x = avg_score$predicted_score, y = avg_score$predicted_score, colour = avg_score$genre), 
               size = 2, shape = 21, stroke = 2) + 
    geom_text(aes(x = avg_score[seq(1, dim(avg_score)[1], 2), ]$predicted_score, 
                   y = avg_score[seq(1, dim(avg_score)[1], 2), ]$predicted_score, 
                   label = avg_score[seq(1, dim(avg_score)[1], 2), ]$genre), 
               check_overlap = F, nudge_y = -0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    geom_text(aes(x = avg_score[seq(2, dim(avg_score)[1], 2), ]$predicted_score, 
                   y = avg_score[seq(2, dim(avg_score)[1], 2), ]$predicted_score, 
                   label = avg_score[seq(2, dim(avg_score)[1], 2), ]$genre), 
               check_overlap = F, nudge_y = 0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9)) +
    scale_x_continuous(breaks = c(6, 6.5, 7)) +
    labs(title = "IMDB Score for different genres", x = "Predicted IMDB Score", y = "Observed IMDB Score") +
    theme_bw() + 
    theme(legend.position = "None")
```

*Keywords analysis*

For gross revenue prediction.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
keywords_model_gross <- lm(gross ~ keywords, data = movies_and_keywords)
summary(keywords_model_gross)
intercept3 <- lm(movies_and_keywords$gross ~ keywords_model_gross$fitted)$coefficients[[1]]

movies_and_keywords_full <- data.frame(movies_and_keywords, predicted_gross = keywords_model_gross$fitted)
avg_gross <- movies_and_keywords_full[, 3:4]
avg_gross <- avg_gross[!duplicated(avg_gross$keywords), ]
avg_gross <- avg_gross[order(avg_gross$predicted_gross), ]
rownames(avg_gross) <- 1:dim(avg_gross)[1]

ggplot() + 
    geom_point(aes(x = movies_and_keywords_full$predicted_gross, y = movies_and_keywords_full$gross, 
                   colour = movies_and_keywords_full$keywords), alpha = 0.1) + 
    geom_abline(intercept = intercept3) + 
    geom_point(aes(x = avg_gross$predicted_gross, y = avg_gross$predicted_gross, colour = avg_gross$keywords), 
               size = 2, shape = 21, stroke = 2) + 
    geom_text(aes(x = avg_gross[seq(1, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   y = avg_gross[seq(1, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   label = avg_gross[seq(1, dim(avg_gross)[1], 2), ]$keywords), 
               check_overlap = F, nudge_y = -0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    geom_text(aes(x = avg_gross[seq(2, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   y = avg_gross[seq(2, dim(avg_gross)[1], 2), ]$predicted_gross, 
                   label = avg_gross[seq(2, dim(avg_gross)[1], 2), ]$keywords), 
               check_overlap = F, nudge_y = 0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    scale_y_log10(breaks = c(1, 1e+02, 1e+04, 1e+06, 1e+08, 1e+10), 
                  labels = c("1", "100", "10,000", "1 million", "100 millions", "10 billions"), limits = c(1, 1e+10)) + 
    scale_x_log10(breaks = c(0.3e+08, 0.4e+08, 0.5e+08, 0.6e+08, 0.7e+08), 
                labels = c("30 millions", "40 millions", "50 millions", "60 millions", "70 millions")) +
    labs(title = "Gross Revenue for different keywords", x = "Predicted Gross Revenue", y = "Observed Gross Revenue") +
    theme_bw() + 
    theme(legend.position = "None") +
    annotation_logticks(sides = "tlbr", colour = "gray") 
```

For IMDB score prediction.

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
keywords_model_score <- lm(score ~ keywords, data = movies_and_keywords)
summary(keywords_model_score)
intercept4 <- lm(movies_and_keywords$score ~ keywords_model_score$fitted)$coefficients[[1]]

movies_and_keywords_full <- data.frame(movies_and_keywords, predicted_score = keywords_model_score$fitted)
avg_score <- movies_and_keywords_full[, 3:4]
avg_score <- avg_score[!duplicated(avg_score$keywords), ]
avg_score <- avg_score[order(avg_score$predicted_score), ]
rownames(avg_score) <- 1:dim(avg_score)[1]

ggplot() + 
    geom_jitter(aes(x = movies_and_keywords_full$predicted_score, y = movies_and_keywords_full$score, 
                    colour = movies_and_keywords_full$keywords), alpha = 0.1) + 
    geom_abline(intercept = intercept4) + 
    geom_point(aes(x = avg_score$predicted_score, y = avg_score$predicted_score, colour = avg_score$keywords), 
               size = 2, shape = 21, stroke = 2) + 
    geom_text(aes(x = avg_score[seq(1, dim(avg_score)[1], 2), ]$predicted_score, 
                   y = avg_score[seq(1, dim(avg_score)[1], 2), ]$predicted_score, 
                   label = avg_score[seq(1, dim(avg_score)[1], 2), ]$keywords), 
               check_overlap = F, nudge_y = -0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    geom_text(aes(x = avg_score[seq(2, dim(avg_score)[1], 2), ]$predicted_score, 
                   y = avg_score[seq(2, dim(avg_score)[1], 2), ]$predicted_score, 
                   label = avg_score[seq(2, dim(avg_score)[1], 2), ]$keywords), 
               check_overlap = F, nudge_y = 0.2, nudge_x = 0, size = 3, angle = 45, fontface = "bold") + 
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9)) +
    scale_x_continuous(breaks = c(6.1, 6.3, 6.5, 6.7)) +
    labs(title = "IMDB Score for different keywords", x = "Predicted IMDB Score", y = "Observed IMDB Score") +
    theme_bw() + 
    theme(legend.position = "None")
```

When we actually make predictions based on a linear model for categorical data, the predicted value is equal to the mean of all observations for each categorical value. So, for each genre or keyword, the predicted value of the gross revenue is equal to the mean value of gross revenues of all the movies of that genre or of that keyword, e.g. the predicted gross revenue for a "Drama" movie is equal to the mean of gross revenues of all the observed "Drama" movies.

### Steven

This section tests whether North American movies have a higher mean IMDB score than European ones. Intuitively, one would assume that North American movies score higher than European ones. This intuition stems from the prevalence of North American movies in media and the proven positive effect of media on sales.

H0 -> Europe and North America get equal scores

```{r, echo = FALSE, fig.width = 10, fig.align = "center"}

# code to create continent column
movies$continent <- countrycode(as.character(movies$country), "country.name", "continent")

# divide "Americas" into "North Americas" and "South America"
south_America = c("Brazil", "Argentina", "Chile", "Colombia", "Peru")

for (i in 1:nrow(movies)) {
  if (is.na(movies$continent[i])) {
    next
  } else if ((movies$continent[i] == "Americas") & (movies$country[i] %in% south_America)) {
    movies$continent[i] <- "South America"
  } else if ((movies$continent[i] == "Americas") & (!(movies$country[i] %in% south_America))) {
    movies$continent[i] <- "North America"
  } 
}

# make dataframes for North America and Europe
North_America <- movies[movies$continent == "North America",]
Europe <- movies[movies$continent == "Europe",]

# separate IMDB scores 
North_America <- North_America[, c("imdb_score", "continent")]
Europe <- Europe[, c("imdb_score", "continent")]

t.test(Europe$imdb_score, North_America$imdb_score)

# combine two data frames
comb <- rbind(Europe, North_America)

# plot densities
ggplot(comb, aes(x = imdb_score, fill = continent)) +
    geom_density(alpha = 0.5) +
    theme_bw() +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    labs(title = "", x = "IMDB Score", y = "Density") +
    theme(legend.title = element_blank())
```

### Director data impact on gross revenue

```{r echo=FALSE, message=FALSE, fig.width = 10, fig.align = "center"}
##plot for gross revenue vs # of movies
ggplot(movieswithdirectordata, aes(x = dir_number_of_movies, y = gross)) + 
    geom_jitter(alpha = 0.2, width = 1) + 
    geom_smooth() +
    theme_bw() +
    labs(x = "Number of movies in sample", y = "Gross Revenue") + scale_y_continuous(label = human_usd)
```

```{r echo=FALSE, message=FALSE, fig.width = 10, fig.align = "center"}
##plot for imdb rating vs # of movies
ggplot(movieswithdirectordata, aes(x = dir_number_of_movies, y = imdb_score)) + 
    geom_jitter(alpha = 0.2, width = 1) + 
    geom_smooth() +
    theme_bw() +
    labs(x = "Number of movies in sample", y = "IMDB Score") +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10))
```

```{r echo=FALSE}
##cor test for imdb rating vs # of movies
cor.test(movieswithdirectordata$imdb_score,movieswithdirectordata$dir_number_of_movies)
##does seem like very loosely positively correlated and is probably because of the correlation with budget- more analysis to come.
##cor test for gross score vs # of movies
cor.test(movieswithdirectordata$gross,movieswithdirectordata$dir_number_of_movies)
##does seem like somewhat positively correlated - although we can see from the graph that this doesn't seem linear.
```

These correlation tests do infer that there is a slight positive correlation between the two outcome variables (gross and imdb score) and the # of movies the director has in the sample. However, the impact on gross revenue does not look to be linear, and neither of the correlations seem to be particularly strong. Whether or not a director is prolific does not seem to have a strong impact on the quality (as proxied by imdb score) or popularity (as proxied by gross revenue) of a movie.

If we look at the categorical variable of whether or not a director has directed >10 movies, then we can see these distributions look slightly different:

```{r echo=FALSE}
ggplot(movieswithdirectordata, aes(x=1, y = gross, fill = more_than_ten_movies)) + geom_boxplot() + facet_grid(. ~ more_than_ten_movies) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) + labs(x="", title="Gross revenue distribution by \n number of movies per director") + scale_y_continuous(label=human_num) + theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "None") 

ggplot(movieswithdirectordata, aes(x = factor(more_than_ten_movies), y = gross, fill = factor(more_than_ten_movies))) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    theme_bw() +
    labs(x = "", y = "Gross", title = "Gross revenue distribution by \n number of movies per director") +
    scale_y_continuous(label = human_num) + 
    theme(axis.title.x = element_blank(), axis.ticks.x = element_blank(), legend.position = "None", panel.grid.major.x = element_blank()) +
    scale_x_discrete(labels = c("More than 10", "Fewer than 10"))
```

The plots seem to suggest that the movies where the director has 10+ movies in the sample have a higher mean and a lower variance of gross revenue. However, this may be largely explained by the number of observations in each sample. To determine whether the change is statistically significant we run a t test and an f test.

```{r echo = FALSE}
t.test(movieswithdirectordata$gross[movieswithdirectordata$more_than_ten_movies=="10+"], movieswithdirectordata$gross[movieswithdirectordata$more_than_ten_movies=="Fewer than 10"], alternative="greater")

var.test(movieswithdirectordata$gross[movieswithdirectordata$more_than_ten_movies=="10+"], movieswithdirectordata$gross[movieswithdirectordata$more_than_ten_movies=="Fewer than 10"], alternative="greater")
```

The data therefore suggests that the average gross revenue is higher for movies where the director has over 10 movies in the sample - which gives evidence to the claim that prolific directors are produce more popular movies (if we see gross revenue as a proxy for popularity).

Also, the opposite of the initial intuition appears to be the case for variance, the movies made by directors with over 10 movies in the sample has higher variance than others. This can be explained by the much larger number of movies made by directors with fewer than 10 movies.

# Predictive Data Analysis

## Model Building and Justification

Multiple models were created to predict gross revenue based on input parameters. Two "full" models were build using all data available, to determine which was the most effective when tested on the test set, and one "known" model was built based on variables that would normally be available *before* a movie is released.


### Second full model

```{r echo=FALSE}
##Data Preparation for model building

##create a summary for directors with count of instances in the sample
traindirectorsummary <- ddply(train, ~ director_name,summarise, number_of_movies=length(director_name))
##add a categorical variable for ten movies or more
traindirectorsummary$more_than_ten_movies <- rep("Fewer than 10", nrow(traindirectorsummary))
traindirectorsummary$more_than_ten_movies[traindirectorsummary$number_of_movies>10] <- "10+"
trainwithdirectordata <- merge(train, traindirectorsummary[,c("director_name","more_than_ten_movies")], by="director_name")
##set factors so that Fewer than Ten is the default variable, and 10+ will show in the model
trainwithdirectordata$more_than_ten_movies <- factor(trainwithdirectordata$more_than_ten_movies, levels=c("Fewer than 10", "10+"))
trainwithdirectordata$PG_13 <- "Not PG-13"
trainwithdirectordata$PG_13[trainwithdirectordata$content_rating=="PG-13"] <- "PG-13"
trainwithdirectordata$PG_13 <- factor(trainwithdirectordata$PG_13, levels=c("Not PG-13", "PG-13"))
## merge with genre data based on title_year
## column subset 3:26 is to remove duplicating the score and gross columns)
trainwithdirectorandgenredata <- merge(movies_and_genres_wide[3:26], trainwithdirectordata, by="movie_title")
```
_Model summary_
```{r echo=FALSE}
fullmodel <- lm(gross ~ budget + num_voted_users + PG_13 + duration + cast_total_facebook_likes + director_facebook_likes + Animation + Family + Mystery + Drama + num_user_for_reviews,  data=trainwithdirectorandgenredata[trainwithdirectorandgenredata$title_year >=2010,])
summary(fullmodel)
```

####Justification

A final model is built using data for movies created post 2010, this is because some of our predictive variables (e.g. facebook likes) are only relevant as predictive variables since facebook has become widely popular for celebrities and movies.

####Variables included in the model:
* Inferential analysis showed that the budget of a movie is positively correlated with the gross revenue, which can be interpreted as movie-makers being wise enough to get a high return on investment.
* Although IMDB score can be seen as the "quality" of a movie, as voted on by the public. At first look this variable is positively correlated with the gross revenue, but interestingly the coefficient for this variable is negative once the "number of users voted" variable is included. An interpretation of this is that the popularity of a movie is more fully explained by the number of people reviewing the movie, and after this is taken into account, the movies with a higher "quality", as measured by imdb score, actually do less well in the box office. This could be because people are more likely to go and vote on imdb for movies they liked, and also for the obvious reason that people are more likely to go and vote on imdb for movies they have seen, so number of user votes will be linked to number of cinema tickets sold, which is linked to gross revenue. If we include number of voted users then the imdb score is statistically insignificant so is removed from the analysis.
* Inferential analysis also showed that for some ratings (e.g. PG-13) there was some impact on gross revenue, so rating has been included in the model to include these effects.
* The duration, when included into the model has a statistically significant positive coefficient, this could be interpreted as movie-goers perceiving longer movies as more value for money or higher quality.
* Cast total facebook likes can also be seen as a potential predictor for gross revenue, as in theory the more popular the actor (measured by facebook likes), the more people will go to see the movie to see that actor, the more tickets are sold and therefore the higher the revenue. We can see from the positive coefficient that this seems to be reflected in the data.
* Director facebook likes is statistically significant when included into the model, interestingly with a negative coefficient. Again, this variable is at first glance positively correlated with the gross revenue, however once you take into account the number of voted users, this relationship is reversed, potentially for similar reasons to the above.
* Movie facebook likes is also statistically significant when included into the model, this can be interpreted as a proxy for the popularity of the movie, and also could be that the more people who saw the movie (based on gross revenue), the more people then subsequently liked the page.
* Key genres have been included into the model if they had statistically significant predictive power, there is a risk of overfitting here, so the variables that have been included are those that have a logical intuition, for example animated and family films are possibly more likely to be targeted to a younger audience, which may therefore have larger potential viewership, and Drama movies are the   

###Not included into the model
* Movie title, director names and actor names were not included into the variable as there many different values for these variables with a small number of observations (usually one observation) for each.
* Plot keywords were not included as there was a high number of possible values, and they were not statistically significant when included into the model.
* Number of critic reviews is quite highly correlated with the number of user reviews, with a correlation coefficient of `r round(cor(movies$num_user_for_reviews,movies$num_critic_for_reviews),2)`. So it was decided to include only one of these variable into the model, in this case number of user reviews.
* When decade is included then none are found to be statistically significant, after other variables are included.
```{r echo=FALSE, fig.width = 3, fig.height=2.5, out.extra='style="float:right"'}
ggplot(movies, aes(x=color)) + geom_bar() + xlab("")
```
* When color is included into the model then none of the options are found to be statistically significant, there is also not a very large variation in this variable in the sample set (seen right).
* When either language or country are included into the model, the R squared does go up, but by a small amount, and this also includes a lot of additional values to be interpreted, so the model loses some interpretability. Due to this, these factors have been left out. 
* The multiple actor "facebook likes" variables are mostly correlated with each other, as can be seen from the correlation matrix, so the total cast facebook likes has been chosen as the "overall" variable to explain the effects of facebook popularity of the cast.
* The number of faces in the poster has not been included into the model, when included it is only slightly statistically significant, and the intuition behind this variable is unclear, so including it may lead to model overfitting.
* IMDB score as discussed above.
* The number of users for review has been included as it is statistically significant and may be correlated due to the two possible mechanisms that reviews may encourage more people to watch the movie, or the more people that see the movie, the more reviews are left.
* Director number of movies, although significant individually, when other variables are taken into account loses its statistical significance, so is omitted from the model.

### First Full Model

```{r linearmodel, echo=FALSE}

trainwithdirectorandgenredata$us_or_others <- trainwithdirectorandgenredata$country
trainwithdirectorandgenredata$us_or_others[trainwithdirectorandgenredata$country != "USA"] <- "Non-USA"
trainwithdirectorandgenredata$english <- factor(trainwithdirectorandgenredata$language == "English", levels = c(TRUE, FALSE), labels = c("English", "Non-English"))
fbmodel <- lm(gross ~ budget + movie_facebook_likes + cast_total_facebook_likes + director_facebook_likes 
              + imdb_score + PG_13 + Action + Adventure + Fantasy + Family + Western + Drama + Crime 
              + Biography + Documentary + us_or_others + english, 
              data = trainwithdirectorandgenredata)
summary(fbmodel)

fbmodel2010 <- lm(gross ~ budget + movie_facebook_likes + cast_total_facebook_likes 
              + director_facebook_likes + imdb_score + PG_13 + Action + Adventure + Fantasy + Family 
              + Western + Drama + Crime + Biography + Documentary + us_or_others + english, 
              data = trainwithdirectorandgenredata[trainwithdirectorandgenredata$title_year >= 2010, ])
summary(fbmodel2010)

```


####Third Model, with only pre-known variables

```{r echo=FALSE}
knownvariablesmodel <- lm(gross ~ budget + PG_13 + duration + cast_total_facebook_likes + director_facebook_likes + Animation + Family + Mystery + Drama + more_than_ten_movies, data=trainwithdirectorandgenredata[trainwithdirectorandgenredata$title_year>=2010,])
summary(knownvariablesmodel)
```

To build a model to predict revenue of movies that have not yet been released, we include only variables that are known before the time of release. Our dataset provided us with number of facebook likes at a specific point in time, and to use this as part of our predictive model we would need to analyse number of facebook likes before the movie was released, however we will use what we currently have as a proxy to build the model. This model has lower predictive power (adjusted R squared of `r summary(knownvariablesmodel)$adj.r.squared`), but could be used in a more useful business context.

###Model Performance
*we will then test this model using the test dataset, make a plot of the predictions against the actual values, and calculate the MSE/other success statistics*

```{r conditiontestdata, echo=FALSE}
##Data Preparation for model building

##create a summary for directors with count of instances in the sample
testdirectorsummary <- ddply(test, ~ director_name,summarise, number_of_movies=length(director_name))
##add a categorical variable for ten movies or more
testdirectorsummary$more_than_ten_movies <- rep("Fewer than 10", nrow(testdirectorsummary))
testdirectorsummary$more_than_ten_movies[testdirectorsummary$number_of_movies>10] <- "10+"
testwithdirectordata <- merge(test, testdirectorsummary[,c("director_name","more_than_ten_movies")], by="director_name")
##set factors so that Fewer than Ten is the default variable, and 10+ will show in the model
testwithdirectordata$more_than_ten_movies <- factor(testwithdirectordata$more_than_ten_movies, levels=c("Fewer than 10", "10+"))
testwithdirectordata$PG_13 <- "Not PG-13"
testwithdirectordata$PG_13[testwithdirectordata$content_rating=="PG-13"] <- "PG-13"
testwithdirectordata$PG_13 <- factor(testwithdirectordata$PG_13, levels=c("Not PG-13", "PG-13"))
## merge with genre data based on movie_title
## column subset 3:26 is to remove duplicating the score and gross columns)
test <- merge(movies_and_genres_wide[3:26], testwithdirectordata, by="movie_title")

test$us_or_others <- test$country
test$us_or_others[test$country != "USA"] <- "Non-USA"
test$english <- factor(test$language == "English", levels = c(TRUE, FALSE), labels = c("English",
                                                                                       "Non-English"))
```

Model including all data:
```{r echo=FALSE}
pre2010model <- lm(gross ~ budget + num_voted_users + PG_13 + duration + cast_total_facebook_likes + director_facebook_likes + Animation + Family + Mystery + Drama + num_user_for_reviews + more_than_ten_movies, data=trainwithdirectorandgenredata)
summary(pre2010model)
```

```{r prediction, echo = FALSE, results = TRUE}

predpre <- predict(pre2010model, test)
rmsepre <- sqrt(mean((predpre - test$gross)^2))
predFB <- predict(fbmodel, test)
rmseFB <- sqrt(mean((predFB - test$gross)^2))

dfpre <- data.frame(y_actual = test$gross, y_predict = predpre)
ggplot(data = dfpre, aes(x = y_predict, y = y_actual)) + geom_point(colour = "red") + 
    geom_abline(colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Actual Gross Revenue(US$)") + coord_cartesian(xlim = c(-0.2e8, 1.5e8), ylim = c(0, 2.5e8))
ggplot(data = dfpre, aes(x = y_predict, y = y_actual - y_predict)) + geom_point(colour = "red") +
    geom_hline(yintercept = 0, colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Residual(US$)") + coord_cartesian(xlim = c(-0.2e8, 2e8), ylim = c(-1.5e8, 1.5e8))

dfFB <- data.frame(y_actual = test$gross, y_predict = predFB)
ggplot(data = dfFB, aes(x = y_predict, y = y_actual)) + geom_point(colour = "red") + 
    geom_abline(colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Actual Gross Revenue(US$)") + coord_cartesian(xlim = c(-0.2e8, 1.5e8), ylim = c(0, 2.5e8))
ggplot(data = dfFB, aes(x = y_predict, y = y_actual - y_predict)) + geom_point(colour = "red") +
    geom_hline(yintercept = 0, colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Residual(US$)") + coord_cartesian(xlim = c(-0.2e8, 2e8), ylim = c(-1.5e8, 1.5e8))

modelperf <- matrix(data = c(rmsepre, rmseFB), nrow = 2)
rownames(modelperf) <- c("Pre Model", "FaceBook Model")
colnames(modelperf) <- c("Root-Mean-Square Error (US$)")
modelperf

predFB2010 <- predict(fbmodel2010, test[test$title_year >= 2010, ])
rmseFB2010 <- sqrt(mean((predFB2010 - test$gross[test$title_year >= 2010])^2))
predFull2010 <- predict(fullmodel, test[test$title_year >= 2010, ])
rmseFull2010 <- sqrt(mean((predFull2010 - test$gross[test$title_year >= 2010])^2))
predKnown2010 <- predict(knownvariablesmodel, test[test$title_year >= 2010, ])
rmseKnown2010 <- sqrt(mean((predKnown2010 - test$gross[test$title_year >= 2010])^2))

dfFB2010 <- data.frame(y_actual = test$gross[test$title_year >= 2010], y_predict = predFB2010)
plot1 <- ggplot(data = dfFB2010, aes(x = y_predict, y = y_actual)) + geom_point(colour = "red") + 
    geom_abline(colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Actual Gross Revenue(US$)") + 
    coord_cartesian(xlim = c(-0.2e8, 1.5e8), ylim = c(0, 2.5e8)) + 
    scale_y_continuous(label = human_usd)  + scale_x_continuous(label = human_usd) 
plot2 <-ggplot(data = dfFB2010, aes(x = y_predict, y = y_actual - y_predict)) + 
    geom_point(colour = "red") + geom_hline(yintercept = 0, colour = "blue") + 
    xlab("Predicted Gross Revenue (US$)") + ylab("Residual(US$)") + 
    coord_cartesian(xlim = c(-0.2e8, 2e8), ylim = c(-1.5e8, 1.5e8)) + 
    scale_y_continuous(label = human_usd) + scale_x_continuous(label = human_usd) 

dfFull2010 <- data.frame(y_actual = test$gross[test$title_year >= 2010], 
                         y_predict = predFull2010)
plot3 <- ggplot(data = dfFull2010, aes(x = y_predict, y = y_actual)) + geom_point(colour = "red") + 
    geom_abline(colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Actual Gross Revenue(US$)") + 
    coord_cartesian(xlim = c(-0.2e8, 1.5e8), ylim = c(0, 2.5e8)) + 
    scale_y_continuous(label = human_usd) + scale_x_continuous(label = human_usd) 
plot4 <- ggplot(data = dfFull2010, aes(x = y_predict, y = y_actual - y_predict)) + 
    geom_point(colour = "red") + geom_hline(yintercept = 0, colour = "blue") + 
    xlab("Predicted Gross Revenue (US$)") + ylab("Residual(US$)") + 
    coord_cartesian(xlim = c(-0.2e8, 2e8), ylim = c(-1.5e8, 1.5e8)) + 
    scale_y_continuous(label = human_usd) + scale_x_continuous(label = human_usd) 

dfKnown2010 <- data.frame(y_actual = test$gross[test$title_year >= 2010], 
                         y_predict = predKnown2010)
plot5 <- ggplot(data = dfKnown2010, aes(x = y_predict, y = y_actual)) + geom_point(colour = "red") + 
    geom_abline(colour = "blue") + xlab("Predicted Gross Revenue (US$)") + 
    ylab("Actual Gross Revenue(US$)") + 
    coord_cartesian(xlim = c(-0.2e8, 1.5e8), ylim = c(0, 2.5e8)) + 
    scale_y_continuous(label = human_usd) + scale_x_continuous(label = human_usd) 
plot6 <- ggplot(data = dfKnown2010, aes(x = y_predict, y = y_actual - y_predict)) + 
    geom_point(colour = "red") + geom_hline(yintercept = 0, colour = "blue") + 
    xlab("Predicted Gross Revenue (US$)") + ylab("Residual(US$)") + 
    coord_cartesian(xlim = c(-0.2e8, 2e8), ylim = c(-1.5e8, 1.5e8)) + 
    scale_y_continuous(label = human_usd) + scale_x_continuous(label = human_usd) 

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, ncol=2)
```

```{r echo=FALSE}
modelperf2010 <- matrix(data = c(rmseFB2010, rmseFull2010, rmseKnown2010), nrow = 3)
rownames(modelperf2010) <- c("FaceBook (Post-2010) Model", "Full (Post-2010) Model", 
                             "Known Variable (Post-2010) Model")
colnames(modelperf2010) <- c("Root-Mean-Square Error (US$)")
modelperf2010

```

#Dicussion

##Conclusion

##Next Steps
*to be completed after our analysis*
*need to write something interesting about our data*

#Appendix

##Nikhita

```{r echo=FALSE}
## IMDB Score analysis for top three ratings
# Boxplot illustration
ggplot(topratedmovies, aes(contentrating, contentscore, fill = contentrating)) + 
    geom_boxplot() + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
    labs(title = "IMDB Score of movies by rating", x = "Content Rating", y = "IMDB Score") + 
    theme_bw() +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) +
    theme(legend.position = "none", axis.ticks.x = element_blank(), panel.grid.major.x = element_blank())

# Does the mean IMDB Score vary with different ratings?
t.test(movies$imdb_score[movies$content_rating == "R"], movies$imdb_score[movies$content_rating == "PG-13"])

t.test(movies$imdb_score[movies$content_rating == "PG-13"], movies$imdb_score[movies$content_rating == "PG"])

t.test(movies$imdb_score[movies$content_rating == "R"], movies$imdb_score[movies$content_rating == "PG"])
```

##Steven

Appendix
```{r, echo = FALSE, fig.width = 10, fig.align = "center"}

# for all countries and all years
# remove NA from title_year column first 
#### should you remove outliers from plot????
temp <- movies[!is.na(movies$title_year),]
ggplot(temp, aes(x = factor(title_year), y = imdb_score, fill = factor(title_year))) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5),legend.position = "None") +
  labs(title = "IMDB scores against year", x = "", y = "IMDB Score") +
  scale_y_continuous(limits = c(2.5, max(movies$imdb_score)))
```


```{r, echo = FALSE, fig.width = 10, fig.align = "center"}


# subset movies data frame to include all movies from 1980 onwards
temp <- movies[movies$title_year >= 1980,]
# plot the range of IMDB scores for all years
p1 <- ggplot(temp, aes(x = factor(title_year), y = imdb_score, fill = factor(title_year))) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5),legend.position = "None") +
  labs(title = "IMDB scores against year, for years with >= 10 entries", x = "", y = "IMDB Score") +
    geom_boxplot(outlier.shape = NA) +
    theme_bw() +
    theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), axis.title.x = element_blank(),
          axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5),legend.position = "None") +
    labs(title = "IMDB scores against year, for years with >= 10 entries", x = "", y = "IMDB Score") +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10))

lm_model <- lm(imdb_score ~ title_year, data = temp)
# make a scatter plot that shows trend in IMDB scores
p2 <- ggplot(temp, aes(x = title_year, y = imdb_score, colour = factor(title_year))) + 
    geom_jitter(alpha = 0.4) +
    geom_abline(intercept = lm_model$coefficients[1], slope = lm_model$coefficients[2], size = 1) +
    theme_bw() +
    labs(x = "", y = "IMDB Score") +
    theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5), legend.position = "None", axis.title.x = element_blank()) +
    scale_x_continuous(breaks = seq(min(temp$title_year), max(temp$title_year), by = 1), 0.5) +
    scale_y_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), limits = c(1, 10)) 

grid.arrange(p1, p2, ncol=1)
```


```{r, echo = FALSE, fig.width = 10, fig.align = "center"}
# create function that converts years into decades
convert_decade <- function(year){
  low <- year - year %% 10
  high <- year - year %% 10 + 9
  paste(as.character(low), as.character(high), sep = "-")
}
# apply previous function
movies$decade <- sapply(movies$title_year, FUN = convert_decade)
```

```{r, echo=FALSE, fig.width = 10, fig.align = "center"}
# For all countries by decade 
# remove entries with NA-NA
temp <- movies[!movies$decade == "NA-NA", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, all countries", x = "", y = "IMDB Score")


# facetgrid of imdb scores over decade for continents
temp <- movies[!is.na(movies$continent), ]
ggplot(temp, aes(y = imdb_score, x = factor(decade), fill = decade)) + 
    geom_boxplot() + 
    labs(title = "IMDB and decades for continents", y = "IMDB score", x = "Decade") + 
    facet_wrap(~ continent) +
    theme_bw() + 
    theme(legend.position = "None",axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5)) +
    annotation_logticks(sides = "lr", colour = "gray")

# for Europe
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$continent == "Europe", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, Europe", x = "", y = "IMDB Score")

# for North America
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$continent == "North America", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, North America", x = "", y = "IMDB Score")

# for France
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "France", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5),legend.position = "None") +
  labs(title = "IMDB scores against decade, France", x = "", y = "IMDB Score")

# for Germany
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "Germany", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, Germany", x = "", y = "IMDB Score")

# for USA
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "USA", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, USA", x = "", y = "IMDB Score")

# for UK
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "UK", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, UK", x = "", y = "IMDB Score")

# for India
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "India", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, India", x = "", y = "IMDB Score")

# for China
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "China", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) +
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, China", x = "", y = "IMDB Score")

# for Hong Kong
temp <- movies[!movies$decade == "NA-NA", ]
temp <- temp[temp$country == "Hong Kong", ]
ggplot(temp, aes(x = decade, y = imdb_score, fill = decade)) + 
  geom_boxplot(outlier.shape = NA) + stat_summary(fun.y=mean, colour="red", geom="point", size=1, show.legend = FALSE) +
  theme(axis.text.x=element_text(angle=45, hjust=0.5, vjust=0.5), legend.position = "None") +
  labs(title = "IMDB scores against decade, Hong Kong", x = "", y = "IMDB Score")
```

The plot above show that there might be a downward trend in IMDB scores over the years. Some years, however, include fewer than ten movies. To get a more accurate picture of the development of IMDB scores only years with ten or more entries will be plotted below.

The plots above give a less biased represenation of the development of IMDB scores. The scores now appear more constant over the years. Although minimal, the scatter plot reveals that there is still a slight downward trend in scores.


##Cecilia

```{r echo=FALSE}

#Analysis on the effect of budget on gross profit margin

#create grossprofit column
movieswprofit <- data.frame(movies)
movieswprofit$grossprofitmargin <- (movieswprofit$gross - movieswprofit$budget)/movieswprofit$gross * 100

#scatter plot for budget vs gross profit margin 
ggplot(data = movieswprofit) + geom_point(aes(x = budget, y = grossprofitmargin, colour = "#FF9999")) + scale_x_log10(breaks = c(1e+03, 1e+05, 1e+07, 1e+09), labels = c("1000", "100,000", "10 million", "1000 million")) + theme(legend.position="none") + scale_y_continuous(limits = c(-1000, 100)) + theme(legend.position="none") + labs(x = "Budget in USD", y = "Gross Profit Margin as %")

#covariance test

cov(movieswprofit$budget, movieswprofit$grossprofitmargin, use = "complete.obs") 

#correlation test

cor.test(movieswprofit$budget, movieswprofit$grossprofitmargin, use = "complete.obs")

movieswprofit$profitable <- ifelse(movieswprofit$grossprofitmargin >= 0, "yes", "no")
table(movieswprofit$profitable)

```

```{r, echo = FALSE}

#plot for budget vs imdb score for countries

ggplot(data = budgetcountry) + geom_jitter(aes(x = budget, y = imdb_score, color=country, alpha = 0.1)) + labs(x = "Budget", y = "IMDB Score") + scale_x_log10(breaks = c(1e+03, 1e+05, 1e+07, 1e+09), labels = c("1000", "100,000", "10 million", "1000 million"))
```

```{r, echo = FALSE}

#plot for budget vs gross for countries

ggplot(data = budgetcountry) + geom_jitter(aes(x = budget, y = gross, color=country, alpha = 0.1)) + labs(x = "Budget", y = "Gross Revenue") + scale_x_log10() 

```


##Siow Meng

##George

##Louise

```{r echo = FALSE, message = FALSE, fig.width = 3, fig.height=3, fig.align = "center" }
##plot for budget vs number of directors in sample
ggplot(movieswithdirectordata, aes(x = dir_number_of_movies, y = budget)) + 
    geom_jitter(alpha = 0.1, width = 1) +
    theme_bw() + 
    labs(x = "Number of movies by director in sample", y = "Budget") + 
    scale_y_continuous(label = human_usd) + 
    scale_x_continuous(breaks = c(0, 5, 10, 15, 20, 25, 30), limits = c(0, 30))
```

If we then split this out by decades, we can see the below:
```{r echo = FALSE}
##add the decades in as per Steven's code (note: potentially change into a function?)
movieswithdirectordata$decade <- sapply(movieswithdirectordata$title_year, FUN = convert_decade)
```

```{r echo = FALSE, fig.width = 10, fig.align = "center", warning = FALSE, message = FALSE}
ggplot(movieswithdirectordata, aes(x = dir_number_of_movies, y = gross, colour = decade)) + 
    geom_jitter(alpha = 0.1) + 
    scale_y_continuous(label = human_usd) + 
    scale_x_continuous(breaks = c(0, 5, 10, 15, 20, 25, 30), limits = c(0, 30)) +
    theme_bw() +
    labs(title = "Gross Revenue by\n number of movies per director\n by decades", x = "Number of movies\nper director", y = "Gross Revenue") + 
    facet_wrap(~ decade, nrow = 4) + 
    theme(legend.position = "None") + 
    geom_smooth(color="#000000")
```

As the number of data elements in the sample grows for each decade, a geomtrical pattern also seems to emerge, which is an upwards trend of gross revenue by movies per director up to about 10 movies per director, andthen a less clear trend for movies for movies with 10+ movies per director.

#To be removed- Notes and comments:

At the end of the assignment we should go back to:

* Check coding standards are consistent (and align with his recommendation - http://adv-r.had.co.nz/Style.html)
* Check language is consistent (tense / case)
* Convert ggplots into the same theme - colour scheme, fonts, etc.
* All assumptions have been noted in the appropriate sections
* We think we're roughly aiming for 20ish pages - tbd at a later stage
* Make sure we don't use language that implies causation when we can only infer correlation
* Double check each others' analyses for Simpson's paradox.
* Maybe put all libraries at the top?

